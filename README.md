# GPU Passthrough - åŸºçº¿å®‰è£…ä¸éªŒè¯è‡ªåŠ¨åŒ– (2025 ç‰ˆæœ¬)

è¿™ä¸ªé¡¹ç›®æä¾›åŸºäº Ansible çš„ GPU æœºå™¨åŸºçº¿å®‰è£…å’ŒéªŒè¯è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆï¼ŒåŸºäº NVIDIA å®˜æ–¹å·¥å…·å’Œ 2024-2025 å¹´æœ€æ–°çš„å¼€æºç¤¾åŒºæœ€ä½³å®è·µã€‚

> **ğŸ†• 2025 å¹´æ›´æ–°**: æ–°å¢ CPU æ€§èƒ½ä¼˜åŒ–ã€NUMA é…ç½®ã€å®Œæ•´ç³»ç»ŸéªŒè¯ã€é€šè®¯å¸¦å®½æµ‹è¯•ã€æ¨¡å‹è®­ç»ƒåŸºå‡†æµ‹è¯•ã€GPU-CUDA å…¼å®¹æ€§è‡ªåŠ¨åŒ¹é…ã€NGC å®¹å™¨é•œåƒç®¡ç†ã€**æ…¢èŠ‚ç‚¹æ£€æµ‹**

## é¡¹ç›®ç›®æ ‡

1. **è‡ªåŠ¨åŒ–å®‰è£…**: é€šè¿‡ Ansible è‡ªåŠ¨åŒ–å®‰è£… GPU æœºå™¨çš„åŸºçº¿ç¯å¢ƒï¼ˆé©±åŠ¨ã€CUDAã€å®¹å™¨è¿è¡Œæ—¶ï¼‰
2. **ğŸ†• æ™ºèƒ½ CUDA é€‰æ‹©**: è‡ªåŠ¨æ£€æµ‹ GPU å‹å·å¹¶é€‰æ‹©å¯¹åº”çš„ CUDA å’Œé©±åŠ¨ç‰ˆæœ¬
3. **CPU æ€§èƒ½ä¼˜åŒ–**: ä¼˜åŒ– CPU é…ç½®ä»¥æœ€å¤§åŒ– GPU å·¥ä½œè´Ÿè½½æ€§èƒ½ï¼ˆNUMAã€é¢‘ç‡è°ƒèŠ‚ã€Turbo Boost ç­‰ï¼‰
4. **å…¨é¢éªŒè¯**: æä¾›å¤šçº§åˆ«çš„éªŒè¯è„šæœ¬ï¼Œæ£€æŸ¥ CPUã€GPUã€NUMAã€IOMMUã€PCIe ç­‰æ‰€æœ‰é…ç½®
5. **ğŸ†• é€šè®¯å¸¦å®½æµ‹è¯•**: PCIeã€NVLinkã€RDMA å¸¦å®½æµ‹è¯•ï¼Œä¸æ€§èƒ½åŸºçº¿å¯¹æ¯”
6. **ğŸ†• æ¨¡å‹è®­ç»ƒåŸºå‡†**: NCCL é›†åˆé€šä¿¡æµ‹è¯•ã€Megatron-LM è®­ç»ƒååé‡æµ‹è¯•
7. **ğŸ†• NGC å®¹å™¨ç®¡ç†**: è‡ªåŠ¨åŒ–æ‹‰å–å’Œç®¡ç† NVIDIA NGC é•œåƒï¼ˆPyTorchã€NeMoã€Triton ç­‰ï¼‰
8. **ğŸ†• æ…¢èŠ‚ç‚¹æ£€æµ‹**: è‡ªåŠ¨æ£€æµ‹é›†ç¾¤ä¸­æ€§èƒ½å¼‚å¸¸çš„èŠ‚ç‚¹å’Œ GPUï¼ˆNVLinkã€PCIeã€NCCL é€šè®¯ï¼‰
9. **å¼€æºæ•´åˆ**: åŸºäº NVIDIA DeepOpsã€GPU Operator ç­‰ 2024-2025 å¹´æœ€æ–°å·¥å…·å’Œæœ€ä½³å®è·µ

## é¡¹ç›®ç»“æ„

```
gpu_passthrough/
â”œâ”€â”€ ansible/                    # Ansible è‡ªåŠ¨åŒ–é…ç½®
â”‚   â”œâ”€â”€ roles/
â”‚   â”‚   â”œâ”€â”€ gpu_baseline/      # GPU åŸºçº¿å®‰è£… role (å« GPU è‡ªåŠ¨æ£€æµ‹)
â”‚   â”‚   â”œâ”€â”€ cpu_optimization/  # ğŸ†• CPU æ€§èƒ½ä¼˜åŒ– role
â”‚   â”‚   â”œâ”€â”€ benchmark_tools/   # ğŸ†• åŸºå‡†æµ‹è¯•å·¥å…· role
â”‚   â”‚   â”œâ”€â”€ ngc_images/        # ğŸ†• NGC å®¹å™¨é•œåƒç®¡ç† role
â”‚   â”‚   â”œâ”€â”€ slow_node_detection/ # ğŸ†• æ…¢èŠ‚ç‚¹æ£€æµ‹ role
â”‚   â”‚   â””â”€â”€ gpu_validation/    # GPU éªŒè¯ role
â”‚   â”œâ”€â”€ playbooks/
â”‚   â”‚   â”œâ”€â”€ setup_gpu_baseline.yml           # GPU åŸºçº¿å®‰è£…
â”‚   â”‚   â”œâ”€â”€ full_deployment_optimized.yml    # ğŸ†• å®Œæ•´ä¼˜åŒ–éƒ¨ç½²
â”‚   â”‚   â”œâ”€â”€ detect_slow_nodes.yml            # ğŸ†• æ…¢èŠ‚ç‚¹æ£€æµ‹
â”‚   â”‚   â””â”€â”€ validate_gpu.yml                 # GPU éªŒè¯
â”‚   â”œâ”€â”€ inventory/             # ä¸»æœºæ¸…å•
â”‚   â””â”€â”€ ansible.cfg
â”œâ”€â”€ scripts/                    # éªŒè¯å’Œç›‘æ§è„šæœ¬
â”‚   â”œâ”€â”€ install/               # ğŸ†• å®‰è£…è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ install_gpu_driver.sh  # ğŸ†• GPU é©±åŠ¨å®‰è£…è„šæœ¬ï¼ˆå¤šæ–¹æ³•æ”¯æŒï¼‰
â”‚   â”‚   â””â”€â”€ build_precompiled_driver.sh # ğŸ†• é¢„ç¼–è¯‘é©±åŠ¨æ„å»ºè„šæœ¬
â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”œâ”€â”€ quick_check.sh     # å¿«é€ŸéªŒè¯
â”‚   â”‚   â”œâ”€â”€ system_check.sh    # ğŸ†• å…¨é¢ç³»ç»ŸéªŒè¯
â”‚   â”‚   â”œâ”€â”€ rdma_check.sh      # ğŸ†• RDMA ç¯å¢ƒéªŒè¯
â”‚   â”‚   â”œâ”€â”€ bandwidth_test.sh  # ğŸ†• å¸¦å®½æµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ intra_node_bandwidth_check.sh   # ğŸ†• èŠ‚ç‚¹å†…éƒ¨å¸¦å®½æ£€æŸ¥
â”‚   â”‚   â”œâ”€â”€ inter_node_nccl_check.sh        # ğŸ†• è·¨èŠ‚ç‚¹ NCCL é€šè®¯æ£€æŸ¥
â”‚   â”‚   â”œâ”€â”€ detect_slow_nodes.sh            # ğŸ†• ç»¼åˆæ…¢èŠ‚ç‚¹æ£€æµ‹å·¥å…·
â”‚   â”‚   â””â”€â”€ gpu_health.py      # GPU å¥åº·æ£€æŸ¥
â”‚   â”œâ”€â”€ benchmarks/            # ğŸ†• åŸºå‡†æµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ nccl_benchmark.sh  # NCCL æµ‹è¯•
â”‚   â”‚   â””â”€â”€ megatron_benchmark.sh # Megatron è®­ç»ƒåŸºå‡†
â”‚   â”œâ”€â”€ utils/                 # å·¥å…·è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ performance_baselines.py # æ€§èƒ½åŸºçº¿æ•°æ®åº“
â”‚   â”‚   â”œâ”€â”€ cuda_compatibility.py    # ğŸ†• GPU-CUDA å…¼å®¹æ€§æ•°æ®åº“
â”‚   â”‚   â”œâ”€â”€ ngc_images.py            # ğŸ†• NGC é•œåƒæ³¨å†Œè¡¨
â”‚   â”‚   â”œâ”€â”€ ngc_manager.sh           # ğŸ†• NGC é•œåƒç®¡ç†å·¥å…·
â”‚   â”‚   â””â”€â”€ manage_precompiled_drivers.sh # ğŸ†• é¢„ç¼–è¯‘é©±åŠ¨ç®¡ç†å·¥å…·
â”‚   â””â”€â”€ monitoring/            # ç›‘æ§è„šæœ¬
â”œâ”€â”€ docs/                       # æ–‡æ¡£
â”‚   â”œâ”€â”€ research.md            # å¼€æºé¡¹ç›®è°ƒç ”æŠ¥å‘Š
â”‚   â”œâ”€â”€ latest_research_2025.md # ğŸ†• 2024-2025 æœ€æ–°è°ƒç ”
â”‚   â”œâ”€â”€ bandwidth_and_benchmarks.md # ğŸ†• å¸¦å®½æµ‹è¯•å’ŒåŸºå‡†æµ‹è¯•æŒ‡å—
â”‚   â”œâ”€â”€ cuda_compatibility_and_ngc.md # ğŸ†• CUDA å…¼å®¹æ€§å’Œ NGC é•œåƒæŒ‡å—
â”‚   â”œâ”€â”€ gpu_driver_installation_methods.md # ğŸ†• GPU é©±åŠ¨å®‰è£…æ–¹æ³•æŒ‡å—
â”‚   â”œâ”€â”€ precompiled_driver_guide.md  # ğŸ†• é¢„ç¼–è¯‘é©±åŠ¨å®Œæ•´æŒ‡å—
â”‚   â”œâ”€â”€ slow_node_detection.md       # ğŸ†• æ…¢èŠ‚ç‚¹æ£€æµ‹å®Œæ•´æŒ‡å—
â”‚   â”œâ”€â”€ best_practices.md      # ğŸ†• æœ€ä½³å®è·µæŒ‡å—
â”‚   â”œâ”€â”€ QUICKSTART.md          # ğŸ†• å¿«é€Ÿå¼€å§‹æŒ‡å—
â”‚   â””â”€â”€ implementation_plan.md # å®æ–½æ–¹æ¡ˆ
â””â”€â”€ README.md
```

## æ ¸å¿ƒåŠŸèƒ½

### 1. GPU åŸºçº¿å®‰è£… (gpu_baseline role)

è‡ªåŠ¨åŒ–å®‰è£…ä»¥ä¸‹ç»„ä»¶ï¼š

- âœ… NVIDIA GPU é©±åŠ¨ï¼ˆæ”¯æŒå¤šç§å®‰è£…æ–¹æ³•ï¼‰
- âœ… CUDA Toolkit
- âœ… NVIDIA Container Toolkit (Docker/containerd)
- âœ… GPU é…ç½®ä¼˜åŒ–ï¼ˆæŒä¹…åŒ–æ¨¡å¼ã€åŠŸç‡é™åˆ¶ç­‰ï¼‰
- âœ… ğŸ†• **GPU è‡ªåŠ¨æ£€æµ‹**: è‡ªåŠ¨è¯†åˆ« GPU å‹å·å¹¶é€‰æ‹©å¯¹åº”çš„ CUDA å’Œé©±åŠ¨ç‰ˆæœ¬
- âœ… ğŸ†• **å¤šç§å®‰è£…æ–¹æ³•**: Nativeã€Driver Containerã€Precompiled

**ğŸ†• GPU-CUDA å…¼å®¹æ€§è‡ªåŠ¨åŒ¹é…**:

æ”¯æŒçš„ GPU å‹å·å’Œè‡ªåŠ¨é€‰æ‹©çš„ CUDA ç‰ˆæœ¬ï¼š

| GPU æ¶æ„ | GPU å‹å· | æ¨è CUDA | æ¨èé©±åŠ¨ |
|---------|---------|-----------|----------|
| Volta | V100 | 12.2 | 535.154.05 |
| Ampere | A100, A800, RTX 3090 | 12.2 | 535.154.05 |
| Hopper | H100, H800 | 12.3 | 545.23.08 |
| Ada Lovelace | RTX 4090 | 12.2 | 535.154.05 |

```bash
# å¯ç”¨è‡ªåŠ¨æ£€æµ‹ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
auto_detect_cuda_version: true

# Ansible ä¼šè‡ªåŠ¨ï¼š
# 1. æ£€æµ‹ GPU å‹å·ï¼ˆlspciï¼‰
# 2. æŸ¥è¯¢å…¼å®¹æ€§æ•°æ®åº“
# 3. é€‰æ‹©æ¨èçš„ CUDA ç‰ˆæœ¬å’Œé©±åŠ¨ç‰ˆæœ¬
# 4. è®°å½•æ£€æµ‹æŠ¥å‘Šåˆ° /var/log/gpu_baseline/gpu_detection.txt
```

**ğŸ†• GPU é©±åŠ¨å®‰è£…æ–¹æ³•**:

æ”¯æŒä¸‰ç§é©±åŠ¨å®‰è£…æ–¹å¼ï¼ŒåŸºäº NVIDIA GPU Operator æ¶æ„ï¼š

| æ–¹æ³• | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| **Native** | ä¼ ç»Ÿå®‰è£…ï¼Œç›´æ¥åœ¨ç³»ç»Ÿä¸Šå®‰è£…é©±åŠ¨ | ä¼ ç»Ÿæ•°æ®ä¸­å¿ƒã€ç‰©ç†æœåŠ¡å™¨ |
| **Driver Container** | å®¹å™¨åŒ–é©±åŠ¨ï¼ŒåŸºäº GPU Operator | Kubernetesã€äº‘åŸç”Ÿç¯å¢ƒ |
| **Precompiled** | é¢„ç¼–è¯‘é©±åŠ¨ï¼Œå¿«é€Ÿéƒ¨ç½² | å¤§è§„æ¨¡éƒ¨ç½²ã€å†…æ ¸ç»Ÿä¸€ç¯å¢ƒ |

```bash
# æ–¹æ³• 1: Native å®‰è£…ï¼ˆé»˜è®¤ï¼‰
ansible-playbook -i inventory/hosts playbooks/setup_gpu_baseline.yml \
  -e "driver_installation_method=native"

# æ–¹æ³• 2: Driver Container å®‰è£…
ansible-playbook -i inventory/hosts playbooks/setup_gpu_baseline.yml \
  -e "driver_installation_method=driver-container"

# æ–¹æ³• 3: ä½¿ç”¨ç‹¬ç«‹è„šæœ¬å®‰è£…
sudo ./scripts/install/install_gpu_driver.sh --method native --auto-detect
sudo ./scripts/install/install_gpu_driver.sh --method driver-container
sudo ./scripts/install/install_gpu_driver.sh --method precompiled
```

**è¯¦ç»†æ–‡æ¡£**:
- [GPU é©±åŠ¨å®‰è£…æ–¹æ³•æŒ‡å—](docs/gpu_driver_installation_methods.md) - ä¸‰ç§æ–¹æ³•çš„è¯¦ç»†å¯¹æ¯”å’Œä½¿ç”¨æŒ‡å—
- [é¢„ç¼–è¯‘é©±åŠ¨å®Œæ•´æŒ‡å—](docs/precompiled_driver_guide.md) - é¢„ç¼–è¯‘é©±åŠ¨çš„æ„å»ºã€éƒ¨ç½²å’Œç®¡ç†

**ğŸ†• é¢„ç¼–è¯‘é©±åŠ¨ç‰¹æ€§**:

é¢„ç¼–è¯‘é©±åŠ¨æä¾›æœ€å¿«çš„éƒ¨ç½²é€Ÿåº¦å’Œæœ€ä½çš„èµ„æºæ¶ˆè€—ï¼Œç‰¹åˆ«é€‚åˆå¤§è§„æ¨¡éƒ¨ç½²ï¼š

```bash
# æ„å»ºé¢„ç¼–è¯‘é©±åŠ¨ï¼ˆä¸€æ¬¡æ€§ï¼‰
./scripts/install/build_precompiled_driver.sh \
    --driver-version 535.154.05 \
    --kernel-version 5.15.0-91-generic \
    --container-build

# æ‰¹é‡æ„å»ºå¤šä¸ªç‰ˆæœ¬
./scripts/install/batch_build_drivers.sh

# ç®¡ç†é¢„ç¼–è¯‘é©±åŠ¨
./scripts/utils/manage_precompiled_drivers.sh list          # åˆ—å‡ºæ‰€æœ‰å¯ç”¨é©±åŠ¨
./scripts/utils/manage_precompiled_drivers.sh install 535.154.05  # å®‰è£…æŒ‡å®šç‰ˆæœ¬
./scripts/utils/manage_precompiled_drivers.sh rollback      # å›æ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬
```

**æ€§èƒ½å¯¹æ¯”**ï¼ˆ100 èŠ‚ç‚¹é›†ç¾¤ï¼‰:

| æŒ‡æ ‡ | ä¼ ç»Ÿå®‰è£… | é¢„ç¼–è¯‘é©±åŠ¨ | èŠ‚çœ |
|------|---------|-----------|------|
| éƒ¨ç½²æ—¶é—´ | ~50 å°æ—¶ | ~3.5 å°æ—¶ | 93% |
| CPU æ—¶é—´ | 100 åˆ†é’Ÿ/èŠ‚ç‚¹ | 5 åˆ†é’Ÿ/èŠ‚ç‚¹ | 95% |
| å†…å­˜ä½¿ç”¨ | 4 GB | 512 MB | 87% |
| ç½‘ç»œå¸¦å®½ | 200 MB/èŠ‚ç‚¹ | 50 MB/èŠ‚ç‚¹ | 75% |

**åŸºäºçš„å¼€æºé¡¹ç›®**:
- [NVIDIA/ansible-role-nvidia-driver](https://github.com/NVIDIA/ansible-role-nvidia-driver)
- [NVIDIA/ansible-role-nvidia-docker](https://github.com/NVIDIA/ansible-role-nvidia-docker)
- [CSCfi/ansible-role-cuda](https://github.com/fgci-org/ansible-role-cuda)
- [datadrivers/ansible-role-docker](https://github.com/datadrivers/ansible-role-docker)

### 2. ğŸ†• CPU æ€§èƒ½ä¼˜åŒ– (cpu_optimization role)

**é’ˆå¯¹ GPU å·¥ä½œè´Ÿè½½ä¼˜åŒ– CPU é…ç½®**ï¼Œæ€§èƒ½æå‡ 20-40%ï¼š

- âœ… CPU Governor è®¾ç½®ï¼ˆPerformance æ¨¡å¼ï¼‰
- âœ… Turbo Boost / Turbo Core å¯ç”¨
- âœ… NUMA ä¼˜åŒ–å’Œäº²å’Œæ€§é…ç½®
- âœ… C-States ä¼˜åŒ–ï¼ˆé™ä½å»¶è¿Ÿï¼‰
- âœ… IOMMU é…ç½®ï¼ˆIntel VT-d / AMD-Viï¼‰
- âœ… PCIe æ€§èƒ½ä¼˜åŒ–
- âœ… Transparent Huge Pages é…ç½®
- âœ… å†…å­˜å‚æ•°è°ƒä¼˜ï¼ˆswappinessã€dirty ratioï¼‰

**å…³é”®ä¼˜åŒ–é¡¹**:
| ä¼˜åŒ–é¡¹ | é»˜è®¤å€¼ | ä¼˜åŒ–å€¼ | æ€§èƒ½æå‡ |
|--------|--------|--------|----------|
| CPU Governor | ondemand/powersave | performance | 10-20% |
| NUMA é…ç½® | è‡ªåŠ¨ | ç»‘å®šåˆ°å¯¹åº”èŠ‚ç‚¹ | 20-40% |
| Turbo Boost | æœªçŸ¥ | å¼ºåˆ¶å¯ç”¨ | 10-15% |
| C-States | æ·±åº¦ç¡çœ  | C1 only | 5-10% (é™ä½å»¶è¿Ÿ) |

**åŸºäºæœ€ä½³å®è·µ**:
- NVIDIA DeepOps é…ç½®
- PyTorch/TensorFlow æ€§èƒ½è°ƒä¼˜æŒ‡å—
- AMD ROCm ç³»ç»Ÿä¼˜åŒ–æ–‡æ¡£

### 3. ğŸ†• å…¨é¢ç³»ç»ŸéªŒè¯ (system_check.sh)

**å®Œæ•´çš„ç³»ç»Ÿé…ç½®éªŒè¯**ï¼Œæ¶µç›– 8 å¤§ç±»æ£€æŸ¥é¡¹ï¼š

1. **CPU é…ç½®**: Governorã€Turbo Boostã€é¢‘ç‡ã€C-States
2. **NUMA é…ç½®**: èŠ‚ç‚¹æ•°ã€GPU äº²å’Œæ€§ã€æ‹“æ‰‘ç»“æ„
3. **IOMMU é…ç½®**: VT-d/AMD-Vi å¯ç”¨ã€IOMMU ç»„ã€å†…æ ¸å‚æ•°
4. **PCIe é…ç½®**: é“¾è·¯é€Ÿåº¦ã€å®½åº¦ã€é”™è¯¯è®¡æ•°ã€ACS
5. **GPU é…ç½®**: é©±åŠ¨ç‰ˆæœ¬ã€æŒä¹…åŒ–æ¨¡å¼ã€æ¸©åº¦ã€ECC é”™è¯¯
6. **å†…å­˜é…ç½®**: THPã€swappinessã€dirty ratio
7. **å†…æ ¸å‚æ•°**: GRUB é…ç½®æ£€æŸ¥
8. **å®¹å™¨è¿è¡Œæ—¶**: Docker/containerd GPU è®¿é—®æµ‹è¯•

**éªŒè¯è¾“å‡º**:
- JSON æ ¼å¼è¯¦ç»†æŠ¥å‘Š
- å½©è‰²ç»ˆç«¯è¾“å‡ºï¼ˆâœ“ é€šè¿‡ / âš  è­¦å‘Š / âœ— å¤±è´¥ï¼‰
- è‡ªåŠ¨åŒ–å¯é›†æˆåˆ° CI/CD

### 4. ğŸ†• é€šè®¯å¸¦å®½æµ‹è¯• (bandwidth_test.sh)

**å®Œæ•´çš„é€šè®¯å¸¦å®½æµ‹è¯•å’Œæ€§èƒ½åŸºçº¿å¯¹æ¯”**ï¼š

#### æœºå†…é€šè®¯æµ‹è¯•
- âœ… **PCIe å¸¦å®½**: Host-Device å’Œ Device-Host ä¼ è¾“ï¼ˆä½¿ç”¨ nvbandwidth, bandwidthTestï¼‰
- âœ… **NVLink å¸¦å®½**: GPU-GPU P2P ä¼ è¾“ï¼ˆä½¿ç”¨ p2pBandwidthLatencyTestï¼‰
- âœ… **GPU æ‹“æ‰‘**: è‡ªåŠ¨æ£€æµ‹ NVLink è¿æ¥å’Œ PCIe é…ç½®

#### æœºé—´é€šè®¯æµ‹è¯•
- âœ… **RDMA å¸¦å®½**: InfiniBand/RoCE ç½‘ç»œæ€§èƒ½ï¼ˆä½¿ç”¨ ib_write_bwï¼‰
- âœ… **GPUDirect RDMA**: GPU ç›´æ¥è®¿é—®è¿œç¨‹ GPU å†…å­˜
- âœ… **ç½‘ç»œæ‹“æ‰‘**: è‡ªåŠ¨æ£€æµ‹ IB è®¾å¤‡å’Œé“¾è·¯é€Ÿåº¦

#### æ€§èƒ½åŸºçº¿æ•°æ®åº“

| GPU å‹å· | å†…å­˜å¸¦å®½ | NVLink BW | PCIe BW | AllReduce (8GPU) |
|---------|---------|-----------|---------|------------------|
| A100-SXM4-80GB | 2039 GB/s | 600 GB/s | 64 GB/s | 250 GB/s |
| H100-SXM5-80GB | 3350 GB/s | 900 GB/s | 128 GB/s | 450 GB/s |
| V100-SXM2-32GB | 900 GB/s | 300 GB/s | 32 GB/s | 180 GB/s |

**ä½¿ç”¨æ–¹å¼**:
```bash
# è¿è¡Œå®Œæ•´å¸¦å®½æµ‹è¯•
./scripts/validation/bandwidth_test.sh

# æˆ–ä½¿ç”¨å¿«æ·å‘½ä»¤ï¼ˆå®‰è£…åï¼‰
gpu-benchmark bandwidth

# æŸ¥çœ‹æ€§èƒ½åŸºçº¿
python3 scripts/utils/performance_baselines.py list
python3 scripts/utils/performance_baselines.py info A100-SXM4-80GB
```

### 5. ğŸ†• NCCL é›†åˆé€šä¿¡æµ‹è¯• (nccl_benchmark.sh)

**æµ‹è¯•åˆ†å¸ƒå¼è®­ç»ƒçš„é›†åˆé€šä¿¡æ€§èƒ½**ï¼š

- âœ… **AllReduce**: æœ€å¸¸ç”¨çš„æ¢¯åº¦åŒæ­¥æ“ä½œ
- âœ… **Broadcast**: å‚æ•°å¹¿æ’­æ€§èƒ½
- âœ… **Reduce-Scatter**: åˆ†å¸ƒå¼ reduce æ“ä½œ
- âœ… **All-Gather**: æ”¶é›†æ“ä½œæ€§èƒ½
- âœ… **å¤šèŠ‚ç‚¹æ”¯æŒ**: MPI é›†æˆï¼Œæ”¯æŒè·¨èŠ‚ç‚¹æµ‹è¯•
- âœ… **æ€§èƒ½åŸºçº¿å¯¹æ¯”**: è‡ªåŠ¨å¯¹æ¯”é¢„æœŸæ€§èƒ½

**é¢„æœŸæ€§èƒ½ï¼ˆBus Bandwidthï¼‰**:
- **A100 8-GPU èŠ‚ç‚¹å†…**: ~250 GB/s
- **H100 8-GPU èŠ‚ç‚¹å†…**: ~450 GB/s
- **A100 è·¨èŠ‚ç‚¹ (IB HDR)**: ~180 GB/s

**ä½¿ç”¨æ–¹å¼**:
```bash
# å•èŠ‚ç‚¹ NCCL æµ‹è¯•
./scripts/benchmarks/nccl_benchmark.sh

# æˆ–ä½¿ç”¨å¿«æ·å‘½ä»¤
gpu-benchmark nccl

# å¤šèŠ‚ç‚¹æµ‹è¯•ï¼ˆéœ€è¦ MPIï¼‰
mpirun -np 64 -N 8 --hostfile hosts \
    /opt/nccl-tests/build/all_reduce_perf -b 8 -e 8G -f 2 -g 1
```

### 6. ğŸ†• Megatron-LM è®­ç»ƒåŸºå‡† (megatron_benchmark.sh)

**å®é™…æ¨¡å‹è®­ç»ƒæ€§èƒ½æµ‹è¯•**ï¼š

- âœ… **GPT æ¨¡å‹è®­ç»ƒ**: æ”¯æŒ GPT-1.2B, GPT-8.3B, GPT-175B
- âœ… **TFLOPS æµ‹é‡**: å®é™…è®¡ç®—ååé‡
- âœ… **MFU è®¡ç®—**: Model FLOP Utilizationï¼ˆæ¨¡å‹åˆ©ç”¨ç‡ï¼‰
- âœ… **æ‰©å±•æ€§æµ‹è¯•**: å¤š GPU/å¤šèŠ‚ç‚¹æ€§èƒ½
- âœ… **æ€§èƒ½åŸºçº¿å¯¹æ¯”**: ä¸å·²çŸ¥åŸºå‡†å¯¹æ¯”
- âœ… **ğŸ†• NGC å®¹å™¨æ”¯æŒ**: æ”¯æŒä½¿ç”¨ NGC NeMo é•œåƒè¿è¡Œ

**æ€§èƒ½åŸºçº¿ (GPT-1.2B å• GPU)**:

| GPU å‹å· | TFLOPS | MFU | Samples/sec |
|---------|--------|-----|-------------|
| V100 | 39 | 30% | 12 |
| A100 | 93.6 | 60% | 28 |
| H100 | 178 | 47% | 45 |

**ä½¿ç”¨æ–¹å¼**:
```bash
# ä½¿ç”¨ NGC NeMo å®¹å™¨è¿è¡Œï¼ˆæ¨èï¼‰
export USE_NGC_CONTAINER=true
MODEL_SIZE=GPT-1.2B ./scripts/benchmarks/megatron_benchmark.sh

# æˆ–ä½¿ç”¨æœ¬åœ° Megatron-LM
export USE_NGC_CONTAINER=false
MODEL_SIZE=GPT-1.2B ./scripts/benchmarks/megatron_benchmark.sh

# è‡ªå®šä¹‰å‚æ•°
MODEL_SIZE=GPT-8.3B BATCH_SIZE=16 NUM_STEPS=200 \
    gpu-benchmark megatron
```

### 7. ğŸ†• NGC å®¹å™¨é•œåƒç®¡ç† (ngc_images role)

**è‡ªåŠ¨åŒ–ç®¡ç† NVIDIA NGC (GPU Cloud) å®¹å™¨é•œåƒ**ï¼š

NVIDIA NGC æä¾›é¢„ä¼˜åŒ–çš„æ·±åº¦å­¦ä¹ å’Œæ¨ç†å®¹å™¨ï¼ŒåŒ…å« CUDAã€cuDNNã€NCCL ç­‰å®Œæ•´å·¥å…·é“¾ã€‚

**æ”¯æŒçš„ NGC é•œåƒ**:

| é•œåƒ | ç‰ˆæœ¬ | ç”¨é€” | ä¸»è¦ç»„ä»¶ |
|------|------|------|----------|
| **pytorch** | 24.01 | è®­ç»ƒ/æ¨ç† | PyTorch 2.3, CUDA 12.3, TensorRT 8.6 |
| **nemo** | 24.01 | LLM è®­ç»ƒ | Megatron-LM 0.5, NeMo 1.22, Transformer Engine |
| **triton** | 24.01 | æ¨ç†æœåŠ¡ | Triton Server 2.42, TensorRT, å¤šåç«¯æ”¯æŒ |
| **tensorflow** | 24.01 | è®­ç»ƒ/æ¨ç† | TensorFlow 2.15, CUDA 12.3 |
| **tensorrt** | 24.01 | æ¨ç†ä¼˜åŒ– | TensorRT 8.6, ONNX Parser |
| **cuda** | 12.3.2 | å¼€å‘ | CUDA Toolkit, NVCC, cuBLAS |
| **rapids** | 24.02 | æ•°æ®ç§‘å­¦ | cuDF, cuML, cuGraph, Dask |
| **deepstream** | 6.4 | è§†é¢‘åˆ†æ | DeepStream, Triton é›†æˆ |

**åŠŸèƒ½ç‰¹æ€§**:

- âœ… **è‡ªåŠ¨æ‹‰å–**: åŸºäº CUDA ç‰ˆæœ¬è‡ªåŠ¨é€‰æ‹©å…¼å®¹é•œåƒ
- âœ… **GPU æµ‹è¯•**: æ‹‰å–åè‡ªåŠ¨éªŒè¯ GPU åŠŸèƒ½
- âœ… **é•œåƒç®¡ç†**: ä¾¿æ·çš„å‘½ä»¤è¡Œå·¥å…·ç®¡ç†é•œåƒ
- âœ… **æ¸…å•æŠ¥å‘Š**: è‡ªåŠ¨ç”Ÿæˆé•œåƒæ¸…å•å’Œæµ‹è¯•æŠ¥å‘Š

**ä½¿ç”¨æ–¹å¼**:

```bash
# æŸ¥çœ‹å¯ç”¨ NGC é•œåƒ
./scripts/utils/ngc_manager.sh list

# æ‹‰å– PyTorch é•œåƒ
./scripts/utils/ngc_manager.sh pull pytorch

# æ‹‰å–ç‰¹å®šç‰ˆæœ¬
./scripts/utils/ngc_manager.sh pull pytorch 24.01

# è¿è¡Œé•œåƒï¼ˆäº¤äº’å¼ï¼‰
./scripts/utils/ngc_manager.sh run pytorch

# æµ‹è¯•é•œåƒ GPU åŠŸèƒ½
./scripts/utils/ngc_manager.sh test pytorch

# æŸ¥çœ‹ CUDA 12.3 å…¼å®¹é•œåƒ
./scripts/utils/ngc_manager.sh cuda 12.3
```

**Ansible è‡ªåŠ¨åŒ–éƒ¨ç½²**:

```yaml
# ansible/roles/ngc_images/defaults/main.yml
ngc_images_to_pull:
  - name: pytorch
    version: "24.01"
  - name: nemo
    version: "24.01"
  - name: triton
    version: "24.01"

# è‡ªåŠ¨æ ¹æ® CUDA ç‰ˆæœ¬é€‰æ‹©é•œåƒ
auto_select_images_by_cuda: true
```

è¿è¡Œ playbook:
```bash
ansible-playbook -i inventory/hosts playbooks/setup_ngc_images.yml
```

**NGC é•œåƒä½¿ç”¨ç¤ºä¾‹**:

```bash
# ä½¿ç”¨ PyTorch é•œåƒè®­ç»ƒ
docker run --gpus all -it --rm \
  --ipc=host --network=host \
  -v $HOME/workspace:/workspace \
  nvcr.io/nvidia/pytorch:24.01-py3

# ä½¿ç”¨ Triton éƒ¨ç½²æ¨ç†æœåŠ¡
docker run --gpus all -it --rm \
  -p 8000:8000 -p 8001:8001 -p 8002:8002 \
  -v /path/to/models:/models \
  nvcr.io/nvidia/tritonserver:24.01-py3 \
  tritonserver --model-repository=/models
```

### 8. ğŸ†• æ…¢èŠ‚ç‚¹æ£€æµ‹ (Slow Node Detection)

**è‡ªåŠ¨æ£€æµ‹ GPU é›†ç¾¤ä¸­æ€§èƒ½å¼‚å¸¸çš„èŠ‚ç‚¹**ï¼ŒåŸºäºä¸šç•Œæœ€ä½³å®è·µï¼ˆMicrosoft Azure DGX Cloudã€Together.AIï¼‰ï¼š

#### æ£€æµ‹æ–¹æ³•

**1. èŠ‚ç‚¹å†…éƒ¨å¸¦å®½æ£€æµ‹** (`intra_node_bandwidth_check.sh`)
- âœ… **NVLink æ‹“æ‰‘å’ŒçŠ¶æ€**: æ£€æŸ¥ NVLink è¿æ¥æ˜¯å¦ activeï¼Œè¯†åˆ«é™é€Ÿé“¾è·¯
- âœ… **GPU-GPU å¸¦å®½**: ä½¿ç”¨ p2pBandwidthLatencyTestã€nvbandwidth æµ‹é‡ GPU é—´å¸¦å®½
- âœ… **PCIe å¸¦å®½**: Host-to-Device å’Œ Device-to-Host ä¼ è¾“æ€§èƒ½
- âœ… **è‡ªåŠ¨åŸºçº¿å¯¹æ¯”**: ä¸ A100/H100/V100 æ€§èƒ½åŸºçº¿å¯¹æ¯”ï¼Œè¯†åˆ«æ…¢ GPU

**2. è·¨èŠ‚ç‚¹ NCCL é€šè®¯æ£€æµ‹** (`inter_node_nccl_check.sh`)
- âœ… **å¤šæ¬¡è¿­ä»£ç»Ÿè®¡**: è¿è¡Œå¤šæ¬¡ NCCL all-reduce æµ‹è¯•ï¼Œè®¡ç®—å‡å€¼/æ ‡å‡†å·®/æœ€å°å€¼/æœ€å¤§å€¼
- âœ… **æˆå¯¹æµ‹è¯• (Pairwise)**: æµ‹è¯•æ¯å¯¹èŠ‚ç‚¹ä¹‹é—´çš„é€šè®¯æ€§èƒ½ï¼Œè¯†åˆ«é—®é¢˜èŠ‚ç‚¹å¯¹
- âœ… **äºŒåˆ†æœç´¢ (Binary Search)**: å¿«é€Ÿå®šä½æ…¢èŠ‚ç‚¹ï¼ˆé€‚ç”¨äº 4+ èŠ‚ç‚¹ï¼‰
- âœ… **æ€§èƒ½åŸºçº¿å¯¹æ¯”**: ä¸ NCCL æ€§èƒ½åŸºçº¿å¯¹æ¯”ï¼Œæ£€æµ‹ä½äºé˜ˆå€¼çš„èŠ‚ç‚¹

**3. ç»¼åˆæ£€æµ‹å·¥å…·** (`detect_slow_nodes.sh`)
- âœ… **ç»Ÿä¸€ç•Œé¢**: æ•´åˆèŠ‚ç‚¹å†…éƒ¨å’Œè·¨èŠ‚ç‚¹æ£€æµ‹
- âœ… **å¹¶è¡Œæ‰§è¡Œ**: æ”¯æŒå¹¶è¡Œè¿è¡ŒèŠ‚ç‚¹å†…éƒ¨æ£€æŸ¥ï¼ˆæ›´å¿«ï¼‰
- âœ… **è‡ªåŠ¨åŒ–æŠ¥å‘Š**: ç”Ÿæˆç»¼åˆæŠ¥å‘Šï¼Œè¯†åˆ«æ‰€æœ‰é—®é¢˜èŠ‚ç‚¹å’Œ GPU
- âœ… **Ansible é›†æˆ**: é€šè¿‡ playbook è‡ªåŠ¨åŒ–åœ¨æ•´ä¸ªé›†ç¾¤æ‰§è¡Œ

#### æ£€æµ‹åŸç†

åŸºäº **Microsoft Azure** åœ¨ DGX Cloud ä¸­ä½¿ç”¨çš„æ–¹æ³•è®ºï¼š

```
1. è¿è¡Œå¤šæ¬¡ NCCL all-reduce æµ‹è¯•ï¼ˆé»˜è®¤ 10 æ¬¡ï¼‰æ”¶é›†ç»Ÿè®¡æ•°æ®
2. å½“æ€»å¸¦å®½åç¦»åŸºçº¿æ—¶ï¼Œä½¿ç”¨äºŒåˆ†æœç´¢éš”ç¦»æ€§èƒ½ä¸ä½³çš„èŠ‚ç‚¹
3. æ‰§è¡Œæˆå¯¹ NCCL æµ‹è¯•è¯†åˆ«åèŠ‚ç‚¹
4. åˆ†æå“ªäº›èŠ‚ç‚¹åœ¨æ…¢èŠ‚ç‚¹å¯¹ä¸­å‡ºç°é¢‘ç‡æœ€é«˜
```

#### æ€§èƒ½åŸºçº¿

**èŠ‚ç‚¹å†…éƒ¨ï¼ˆ8 GPUs with NVLinkï¼‰**:

| GPU å‹å· | NVLink å• GPU å¸¦å®½ | NCCL AllReduce Bus BW | é˜ˆå€¼ (90%) |
|---------|------------------|---------------------|-----------|
| A100 SXM4 | 600 GB/s | ~250 GB/s | 225 GB/s |
| H100 SXM5 | 900 GB/s | ~350 GB/s | 315 GB/s |
| V100 SXM2 | 300 GB/s | ~180 GB/s | 162 GB/s |

**è·¨èŠ‚ç‚¹ï¼ˆInfiniBandï¼‰**:

| GPU + ç½‘ç»œ | NCCL Bus BW | é˜ˆå€¼ (92%) |
|-----------|------------|----------|
| A100 + IB HDR 200Gb | ~180 GB/s | 165 GB/s |
| A100/H100 + IB NDR 400Gb | ~360 GB/s | 331 GB/s |

#### ä½¿ç”¨æ–¹å¼

**å•èŠ‚ç‚¹å†…éƒ¨æ£€æŸ¥**:
```bash
# å¿«é€Ÿæ£€æŸ¥å•ä¸ªèŠ‚ç‚¹çš„ GPU å¸¦å®½
./scripts/validation/intra_node_bandwidth_check.sh -o results

# è‡ªå®šä¹‰é˜ˆå€¼ï¼ˆ85%ï¼‰
./scripts/validation/intra_node_bandwidth_check.sh -o results -t 85
```

**è·¨èŠ‚ç‚¹ NCCL æ£€æŸ¥**:
```bash
# åˆ›å»ºèŠ‚ç‚¹åˆ—è¡¨
cat > nodes.txt <<EOF
gpu-node1
gpu-node2
gpu-node3
gpu-node4
EOF

# åŸºæœ¬æ£€æŸ¥ï¼ˆå…¨èŠ‚ç‚¹ all-reduceï¼‰
./scripts/validation/inter_node_nccl_check.sh -n nodes.txt -o results

# å¯ç”¨æˆå¯¹æµ‹è¯•ï¼ˆæ£€æµ‹æ‰€æœ‰èŠ‚ç‚¹å¯¹ï¼‰
./scripts/validation/inter_node_nccl_check.sh -n nodes.txt -o results --pairwise

# å¯ç”¨äºŒåˆ†æœç´¢ï¼ˆå¿«é€Ÿå®šä½æ…¢èŠ‚ç‚¹ï¼‰
./scripts/validation/inter_node_nccl_check.sh -n nodes.txt -o results --binary-search

# å®Œæ•´æ£€æµ‹ï¼ˆæˆå¯¹ + äºŒåˆ†æœç´¢ + 20 æ¬¡è¿­ä»£ï¼‰
./scripts/validation/inter_node_nccl_check.sh -n nodes.txt -o results \
  --pairwise --binary-search -i 20
```

**ç»¼åˆæ£€æµ‹ï¼ˆæ¨èï¼‰**:
```bash
# å®Œæ•´é›†ç¾¤æ£€æµ‹ï¼ˆèŠ‚ç‚¹å†…éƒ¨ + è·¨èŠ‚ç‚¹ï¼‰
./scripts/validation/detect_slow_nodes.sh -n nodes.txt -o results

# å¹¶è¡Œæ‰§è¡ŒèŠ‚ç‚¹å†…éƒ¨æ£€æŸ¥ + å®Œæ•´è·¨èŠ‚ç‚¹æµ‹è¯•
./scripts/validation/detect_slow_nodes.sh -n nodes.txt -o results \
  --parallel --pairwise --binary-search

# ä»…èŠ‚ç‚¹å†…éƒ¨æ£€æŸ¥ï¼ˆå¿«é€Ÿï¼‰
./scripts/validation/detect_slow_nodes.sh -n nodes.txt --skip-inter --parallel

# ä»…è·¨èŠ‚ç‚¹æ£€æŸ¥
./scripts/validation/detect_slow_nodes.sh -n nodes.txt --skip-intra --pairwise
```

**Ansible è‡ªåŠ¨åŒ–**:
```bash
# ä½¿ç”¨ Ansible åœ¨æ•´ä¸ªé›†ç¾¤è¿è¡Œæ£€æµ‹
cd ansible

# å®Œæ•´æ£€æµ‹
ansible-playbook -i inventory playbooks/detect_slow_nodes.yml

# è‡ªå®šä¹‰é…ç½®
ansible-playbook -i inventory playbooks/detect_slow_nodes.yml \
  -e slow_node_detection_threshold=92 \
  -e slow_node_detection_pairwise=true \
  -e slow_node_detection_binary_search=true \
  -e slow_node_detection_parallel=true
```

#### æ£€æµ‹è¾“å‡º

æ£€æµ‹å®Œæˆåä¼šç”Ÿæˆè¯¦ç»†æŠ¥å‘Šï¼š

```
results/
â”œâ”€â”€ intra_node_results/           # èŠ‚ç‚¹å†…éƒ¨æ£€æŸ¥ç»“æœ
â”‚   â”œâ”€â”€ node1_<timestamp>/
â”‚   â”‚   â”œâ”€â”€ gpu_info_*.txt
â”‚   â”‚   â”œâ”€â”€ nvlink_topology_*.txt
â”‚   â”‚   â”œâ”€â”€ p2p_bandwidth_summary_*.csv
â”‚   â”‚   â”œâ”€â”€ pcie_bandwidth_summary_*.csv
â”‚   â”‚   â”œâ”€â”€ slow_connections_*.txt    # âš  æ…¢ GPU è¿æ¥ï¼ˆå¦‚æœ‰ï¼‰
â”‚   â”‚   â””â”€â”€ bandwidth_check_report_*.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ inter_node_results/           # è·¨èŠ‚ç‚¹ NCCL æ£€æŸ¥ç»“æœ
â”‚   â”œâ”€â”€ all_nodes_*_stats.txt
â”‚   â”œâ”€â”€ pairwise_results_*.csv
â”‚   â””â”€â”€ nccl_check_report_*.md
â””â”€â”€ slow_node_summary_*.md        # ç»¼åˆæŠ¥å‘Š
```

#### å¸¸è§é—®é¢˜è¯Šæ–­

**é—®é¢˜ç±»å‹ 1: NVLink å¸¦å®½ä½**
```
ç—‡çŠ¶: GPU 0 <-> GPU 1: 150 GB/s (é¢„æœŸ: 300 GB/s)
åŸå› : NVLink cable æ¾åŠ¨æˆ–æ•…éšœ
è§£å†³: é‡æ–°æ’æ‹” cableï¼Œæ£€æŸ¥ nvidia-smi nvlink --status
```

**é—®é¢˜ç±»å‹ 2: PCIe é™é€Ÿ**
```
ç—‡çŠ¶: GPU è¿è¡Œåœ¨ Gen3 x8 (é¢„æœŸ: Gen4 x16)
åŸå› : PCIe æ§½ä½é…ç½®é”™è¯¯
è§£å†³: ç¡®è®¤ GPU å®‰è£…åœ¨æ­£ç¡®çš„ PCIe æ§½ä½ï¼Œæ›´æ–° BIOS
```

**é—®é¢˜ç±»å‹ 3: è·¨èŠ‚ç‚¹é€šè®¯æ…¢**
```
ç—‡çŠ¶: node1 <-> node3 çš„æ‰€æœ‰æˆå¯¹æµ‹è¯•å‡ <100 GB/s
åŸå› : InfiniBand è¿æ¥é—®é¢˜æˆ–ç½‘å¡æ•…éšœ
è§£å†³: æ£€æŸ¥ IB cableï¼ŒéªŒè¯ ibstat è¾“å‡ºï¼Œæ›´æ–° IB é©±åŠ¨
```

**è¯¦ç»†æ–‡æ¡£**: [æ…¢èŠ‚ç‚¹æ£€æµ‹å®Œæ•´æŒ‡å—](docs/slow_node_detection.md)

#### æœ€ä½³å®è·µ

**å®šæœŸæ£€æµ‹é¢‘ç‡**:
- **æ–°é›†ç¾¤éƒ¨ç½²**: ç«‹å³è¿è¡Œå®Œæ•´æ£€æµ‹ä½œä¸ºéªŒæ”¶
- **æ—¥å¸¸è¿è¡Œ**: æ¯å‘¨å¿«é€Ÿæ£€æµ‹ï¼ˆä»…èŠ‚ç‚¹å†…éƒ¨ï¼‰
- **å®šæœŸç»´æŠ¤**: æ¯æœˆå®Œæ•´æ£€æµ‹ï¼ˆåŒ…æ‹¬è·¨èŠ‚ç‚¹ï¼‰
- **é—®é¢˜æ’æŸ¥**: å‘ç°æ€§èƒ½é—®é¢˜æ—¶ç«‹å³è¿è¡Œ

**æ£€æµ‹ç­–ç•¥**:
- **å¿«é€Ÿæ£€æµ‹** (5-10 åˆ†é’Ÿ): ä»…èŠ‚ç‚¹å†…éƒ¨ï¼Œå¹¶è¡Œæ‰§è¡Œ
- **æ ‡å‡†æ£€æµ‹** (30-60 åˆ†é’Ÿ): èŠ‚ç‚¹å†…éƒ¨ + å…¨èŠ‚ç‚¹ NCCL
- **æ·±åº¦æ£€æµ‹** (2-4 å°æ—¶): å®Œæ•´æˆå¯¹æµ‹è¯• + äºŒåˆ†æœç´¢

**è‡ªåŠ¨åŒ–**:
```bash
# ä½¿ç”¨ cron å®šæœŸè¿è¡Œ
# /etc/cron.weekly/gpu_cluster_check
ansible-playbook -i production_inventory playbooks/detect_slow_nodes.yml \
  -e slow_node_detection_skip_inter=true \
  -e slow_node_detection_output_dir=/var/log/slow_node_detection/$(date +%Y%m%d)
```

### 9. ğŸ†• RDMA ç¯å¢ƒéªŒè¯ (rdma_check.sh)

**å…¨é¢æ£€æŸ¥ RDMA/InfiniBand ç¯å¢ƒæ˜¯å¦å‡†å¤‡å°±ç»ª**ï¼Œç”¨äºé«˜æ€§èƒ½é›†ç¾¤é€šè®¯ï¼š

#### æ£€æŸ¥é¡¹ç›®

**1. RDMA å†…æ ¸æ¨¡å—**
- âœ… **æ ¸å¿ƒ RDMA æ¨¡å—**: rdma_cm, ib_core, ib_uverbs, rdma_ucm
- âœ… **ä¼ è¾“å±‚æ¨¡å—**: ib_ipoib, ib_srp, ib_iser ç­‰
- âœ… **å‚å•†é©±åŠ¨**: mlx5_core, mlx4_core (Mellanox/NVIDIA)
- âœ… **GPUDirect RDMA**: nv_peer_mem / nvidia_peermem æ¨¡å—

**2. RDMA è®¾å¤‡çŠ¶æ€**
- âœ… **InfiniBand è®¾å¤‡**: ibstat æ£€æµ‹è®¾å¤‡å’Œç«¯å£çŠ¶æ€
- âœ… **ç«¯å£çŠ¶æ€**: Active/Down çŠ¶æ€ï¼Œé“¾è·¯é€Ÿåº¦ (FDR/EDR/HDR/NDR)
- âœ… **RDMA è®¾å¤‡ä¿¡æ¯**: ibv_devinfo æ£€æµ‹è®¾å¤‡èƒ½åŠ›
- âœ… **é“¾è·¯å±‚**: InfiniBand æˆ– RoCE (Ethernet)

**3. è½¯ä»¶æ ˆå®Œæ•´æ€§**
- âœ… **æ ¸å¿ƒåº“**: libibverbs, librdmacm, rdma-core
- âœ… **è¯Šæ–­å·¥å…·**: infiniband-diags (ibstat, ibv_devinfo ç­‰)
- âœ… **æ€§èƒ½æµ‹è¯•**: perftest (ib_write_bw, ib_read_bw ç­‰)
- âœ… **Subnet Manager**: opensm (InfiniBand å¿…éœ€)

**4. ç½‘ç»œé…ç½®**
- âœ… **IPoIB æ¥å£**: IP over InfiniBand ç½‘ç»œæ¥å£
- âœ… **MTU é…ç½®**: Connected mode (65520) vs Datagram mode (2044)
- âœ… **RoCE æ”¯æŒ**: RDMA over Converged Ethernet æ£€æµ‹
- âœ… **æ¥å£çŠ¶æ€**: UP/DOWN, IP åœ°å€é…ç½®

**5. GPUDirect RDMA ç¯å¢ƒ**
- âœ… **GPU æ£€æµ‹**: NVIDIA GPU å’Œé©±åŠ¨ç‰ˆæœ¬
- âœ… **Peer Memory**: nv_peer_mem æ¨¡å—å’Œ /sys/kernel/mm/memory_peer_target
- âœ… **NUMA äº²å’Œæ€§**: GPU å’Œ IB è®¾å¤‡çš„ NUMA èŠ‚ç‚¹åˆ†å¸ƒ
- âœ… **GPU æ‹“æ‰‘**: NVLink å’Œ PCIe æ‹“æ‰‘ç»“æ„

**6. ç³»ç»Ÿé…ç½®**
- âœ… **IOMMU**: VT-d/AMD-Vi å¯ç”¨çŠ¶æ€å’Œå†…æ ¸å‚æ•°
- âœ… **å†…å­˜é”å®š**: ulimit memlock é…ç½® (åº”ä¸º unlimited)
- âœ… **PCIe çŠ¶æ€**: GPU å’Œ IB è®¾å¤‡çš„ PCIe é“¾è·¯é€Ÿåº¦/å®½åº¦

#### ä½¿ç”¨æ–¹å¼

```bash
# è¿è¡Œ RDMA ç¯å¢ƒæ£€æŸ¥
sudo ./scripts/validation/rdma_check.sh

# æŒ‡å®šè¾“å‡ºç›®å½•
sudo ./scripts/validation/rdma_check.sh /path/to/output_dir
```

#### è¾“å‡ºæŠ¥å‘Š

è„šæœ¬ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
output_dir/
â”œâ”€â”€ rdma_check.json           # JSON æ ¼å¼è¯¦ç»†æŠ¥å‘Š
â”œâ”€â”€ rdma_summary.md           # Markdown æ ¼å¼æ‘˜è¦æŠ¥å‘Š
â”œâ”€â”€ ibstat_output.txt         # ibstat åŸå§‹è¾“å‡º
â”œâ”€â”€ ibv_devinfo_output.txt    # ibv_devinfo åŸå§‹è¾“å‡º
â”œâ”€â”€ rdma_link_output.txt      # rdma link è¾“å‡º
â””â”€â”€ gpu_topology.txt          # GPU æ‹“æ‰‘ä¿¡æ¯
```

#### æŠ¥å‘Šç¤ºä¾‹

```
========================================
RDMA ç¯å¢ƒéªŒè¯
========================================
å¼€å§‹æ—¶é—´: 2025-01-15 10:30:00

1. RDMA å†…æ ¸æ¨¡å—æ£€æŸ¥
========================================
âœ“ [å†…æ ¸æ¨¡å—] rdma_cm: å·²åŠ è½½
âœ“ [å†…æ ¸æ¨¡å—] ib_core: å·²åŠ è½½
âœ“ [å†…æ ¸æ¨¡å—] ib_uverbs: å·²åŠ è½½
âœ“ [å‚å•†é©±åŠ¨] mlx5_core: å·²åŠ è½½
âœ“ [å‚å•†é©±åŠ¨] mlx5_ib: å·²åŠ è½½
âœ“ [GPUDirect] nv_peer_mem: å·²åŠ è½½ (ç‰ˆæœ¬: 1.3-0)

2. RDMA è®¾å¤‡æ£€æŸ¥
========================================
âœ“ [IBè®¾å¤‡] è®¾å¤‡æ•°é‡: 2
âœ“ [IBç«¯å£] mlx5_0:1: Active @ 200 Gb/sec (4X HDR)
âœ“ [IBç«¯å£] mlx5_1:1: Active @ 200 Gb/sec (4X HDR)

æ£€æŸ¥ç»“æœæ‘˜è¦
========================================
  âœ“ é€šè¿‡:  45
  âš  è­¦å‘Š:  3
  âœ— å¤±è´¥:  0

========================================
âœ… RDMA ç¯å¢ƒåŸºæœ¬å°±ç»ª
========================================
```

#### å¸¸è§é—®é¢˜ä¿®å¤

**é—®é¢˜ 1: å†…æ ¸æ¨¡å—æœªåŠ è½½**
```bash
# åŠ è½½ RDMA æ ¸å¿ƒæ¨¡å—
sudo modprobe rdma_cm
sudo modprobe ib_core
sudo modprobe ib_uverbs

# åŠ è½½ Mellanox é©±åŠ¨
sudo modprobe mlx5_core
sudo modprobe mlx5_ib

# åŠ è½½ GPUDirect RDMA
sudo modprobe nv_peer_mem
```

**é—®é¢˜ 2: å†…å­˜é”å®šé™åˆ¶**
```bash
# ç¼–è¾‘ /etc/security/limits.conf
sudo tee -a /etc/security/limits.conf << EOF
* soft memlock unlimited
* hard memlock unlimited
EOF

# é‡æ–°ç™»å½•ç”Ÿæ•ˆ
```

**é—®é¢˜ 3: IB ç«¯å£ Down**
```bash
# æ£€æŸ¥ç‰©ç†è¿æ¥
ibstat

# æ£€æŸ¥é“¾è·¯çŠ¶æ€
ibv_devinfo

# é‡å¯ IB é©±åŠ¨
sudo /etc/init.d/openibd restart
```

**é—®é¢˜ 4: GPUDirect RDMA ä¸å¯ç”¨**
```bash
# å®‰è£… nvidia-peer-memory (CUDA 11.x+)
# Ubuntu/Debian:
git clone https://github.com/Mellanox/nv_peer_memory.git
cd nv_peer_memory
./build_module.sh
sudo ./install.sh

# æˆ–ä½¿ç”¨ MLNX_OFED è‡ªå¸¦çš„ç‰ˆæœ¬
sudo /etc/init.d/nv_peer_mem start
```

#### RDMA æ€§èƒ½æµ‹è¯•

æ£€æŸ¥é€šè¿‡åï¼Œå¯ä»¥è¿›è¡Œ RDMA æ€§èƒ½æµ‹è¯•ï¼š

```bash
# æµ‹è¯• RDMA å†™å¸¦å®½ (éœ€è¦ä¸¤å°ä¸»æœº)
# æœåŠ¡ç«¯
ib_write_bw -d mlx5_0 -a

# å®¢æˆ·ç«¯
ib_write_bw -d mlx5_0 -a <server_ip>

# æµ‹è¯• GPUDirect RDMA (å¦‚æœæ”¯æŒ)
# æœåŠ¡ç«¯
ib_write_bw -d mlx5_0 --use_cuda=0

# å®¢æˆ·ç«¯
ib_write_bw -d mlx5_0 --use_cuda=0 <server_ip>

# é¢„æœŸæ€§èƒ½ (InfiniBand HDR 200Gb/s)
# - ä¸»æœºå†…å­˜: ~23-24 GB/s
# - GPU å†…å­˜ (GPUDirect): ~20-22 GB/s
```

#### å‚è€ƒèµ„æº

- [NVIDIA GPUDirect RDMA å®˜æ–¹æ–‡æ¡£](https://docs.nvidia.com/cuda/gpudirect-rdma/)
- [Mellanox OFED ç”¨æˆ·æ‰‹å†Œ](https://docs.nvidia.com/networking/display/mlnxofedv24010331)
- [Linux RDMA æ ¸å¿ƒæ–‡æ¡£](https://github.com/linux-rdma/rdma-core)
- [InfiniBand æ€§èƒ½è°ƒä¼˜](https://docs.nvidia.com/networking/display/perftuning)

### 10. GPU éªŒè¯æµ‹è¯• (å¤šçº§åˆ«)

#### Level 1: å¿«é€ŸéªŒè¯ (1-5 åˆ†é’Ÿ)
- nvidia-smi å¯ç”¨æ€§æ£€æŸ¥
- GPU è®¾å¤‡æ£€æµ‹
- é©±åŠ¨å’Œ CUDA ç‰ˆæœ¬ç¡®è®¤
- åŸºç¡€å¥åº·æ£€æŸ¥ï¼ˆæ¸©åº¦ã€å†…å­˜ã€PCIeï¼‰

#### Level 2: æ ‡å‡†éªŒè¯ (10-15 åˆ†é’Ÿ)
- Level 1 æ‰€æœ‰æ£€æŸ¥
- DCGM å¿«é€Ÿè¯Šæ–­
- CUDA åŠŸèƒ½æµ‹è¯•
- å®¹å™¨ GPU è®¿é—®æµ‹è¯•
- å†…å­˜å¸¦å®½æµ‹è¯•

#### Level 3: å®Œæ•´éªŒè¯ (30-60 åˆ†é’Ÿ)
- Level 2 æ‰€æœ‰æ£€æŸ¥
- DCGM å®Œæ•´è¯Šæ–­å¥—ä»¶
- GPU-Burn å‹åŠ›æµ‹è¯•
- é•¿æ—¶é—´ç¨³å®šæ€§æµ‹è¯•
- æ€§èƒ½åŸºå‡†æµ‹è¯•

**åŸºäºçš„å·¥å…·**:
- [NVIDIA DCGM](https://github.com/NVIDIA/DCGM) - æ•°æ®ä¸­å¿ƒ GPU ç®¡ç†å™¨
- [NVIDIA Validation Suite (NVVS)](https://docs.nvidia.com/deploy/nvvs-user-guide/)
- [GPU-Burn](https://github.com/wilicc/gpu-burn) - GPU å‹åŠ›æµ‹è¯•
- [gpustat](https://github.com/wookayin/gpustat) - GPU çŠ¶æ€ç›‘æ§
- [nvitop](https://github.com/XuehaiPan/nvitop) - GPU è¿›ç¨‹ç®¡ç†

## å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

**æ§åˆ¶èŠ‚ç‚¹**:
- Ansible >= 2.10
- Python >= 3.8
- SSH è®¿é—®ç›®æ ‡ä¸»æœº

**ç›®æ ‡ä¸»æœº**:
- Ubuntu 20.04/22.04 æˆ– RHEL/CentOS 8+
- è‡³å°‘ 10GB å¯ç”¨ç£ç›˜ç©ºé—´
- NVIDIA GPU ç¡¬ä»¶
- ç®¡ç†å‘˜æƒé™

### å®‰è£…æ­¥éª¤

#### 1. å…‹éš†é¡¹ç›®

```bash
git clone <repository-url>
cd gpu_passthrough
```

#### 2. é…ç½®ä¸»æœºæ¸…å•

ç¼–è¾‘ `ansible/inventory/hosts.yml`:

```yaml
all:
  children:
    gpu_nodes:
      hosts:
        gpu-server-01:
          ansible_host: 192.168.1.101
          ansible_user: ubuntu
```

#### 3. é…ç½®å˜é‡

ç¼–è¾‘ `ansible/inventory/group_vars/gpu_nodes.yml` æ ¹æ®éœ€æ±‚è°ƒæ•´é…ç½®ï¼š

```yaml
# GPU é…ç½®
nvidia_driver_version: "535"
cuda_version: "12-2"
install_cuda: true
install_container_runtime: true
container_runtime: "docker"

# ğŸ†• CPU ä¼˜åŒ–é…ç½®
cpu_governor: "performance"
enable_turbo_boost: true
optimize_numa: true
vm_swappiness: 10
```

#### 4. ğŸ†• å®Œæ•´ä¼˜åŒ–éƒ¨ç½²ï¼ˆæ¨èï¼‰

```bash
cd ansible

# å®Œæ•´éƒ¨ç½²ï¼šGPU åŸºçº¿ + CPU ä¼˜åŒ–
ansible-playbook playbooks/full_deployment_optimized.yml

# éƒ¨ç½²åéœ€è¦é‡å¯ç³»ç»Ÿ
ssh gpu-server-01 sudo reboot
```

#### 5. ğŸ†• è¿è¡Œå…¨é¢ç³»ç»ŸéªŒè¯

```bash
# æ–¹æ³• 1: é€šè¿‡ Ansible playbook
ansible-playbook playbooks/validate_gpu.yml -e "level=standard"

# æ–¹æ³• 2: ç›´æ¥è¿è¡ŒéªŒè¯è„šæœ¬ï¼ˆåœ¨ç›®æ ‡ä¸»æœºä¸Šï¼‰
ssh gpu-server-01
sudo /path/to/scripts/validation/system_check.sh

# æ–¹æ³• 3: å¿«é€Ÿ GPU æ£€æŸ¥
./scripts/validation/quick_check.sh /tmp/gpu_check.json
```

#### æ—§æ–¹å¼ï¼šä»… GPU åŸºçº¿å®‰è£…ï¼ˆä¸å« CPU ä¼˜åŒ–ï¼‰

```bash
cd ansible
ansible-playbook playbooks/setup_gpu_baseline.yml
```

### å•ç‹¬ä½¿ç”¨éªŒè¯è„šæœ¬

```bash
# ğŸ†• å…¨é¢ç³»ç»Ÿæ£€æŸ¥ï¼ˆæ¨èï¼‰
sudo ./scripts/validation/system_check.sh /tmp/system_check.json

# GPU å¿«é€Ÿæ£€æŸ¥
./scripts/validation/quick_check.sh /tmp/gpu_check.json

# Python GPU å¥åº·æ£€æŸ¥
python3 scripts/validation/gpu_health.py -o /tmp/health_report.json -v

# ğŸ†• æŸ¥çœ‹ NUMA å’Œ GPU äº²å’Œæ€§
sudo numa-gpu-info  # éƒ¨ç½²åè‡ªåŠ¨å®‰è£…
```

## é…ç½®è¯´æ˜

### å…³é”®å˜é‡

#### GPU é…ç½®

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `nvidia_driver_version` | "535" | NVIDIA é©±åŠ¨ç‰ˆæœ¬ |
| `cuda_version` | "12-2" | CUDA Toolkit ç‰ˆæœ¬ |
| `install_cuda` | true | æ˜¯å¦å®‰è£… CUDA |
| `install_container_runtime` | true | æ˜¯å¦å®‰è£…å®¹å™¨è¿è¡Œæ—¶ |
| `container_runtime` | "docker" | å®¹å™¨è¿è¡Œæ—¶ç±»å‹ (docker/containerd) |
| `gpu_persistence_mode` | true | GPU æŒä¹…åŒ–æ¨¡å¼ |
| `validation_level` | "quick" | éªŒè¯çº§åˆ« (quick/standard/full) |

#### ğŸ†• CPU ä¼˜åŒ–é…ç½®

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `cpu_governor` | "performance" | CPU é¢‘ç‡è°ƒèŠ‚å™¨ |
| `enable_turbo_boost` | true | å¯ç”¨ Turbo Boost/Turbo Core |
| `optimize_numa` | true | å¯ç”¨ NUMA ä¼˜åŒ– |
| `disable_deep_cstates` | true | ç¦ç”¨æ·±åº¦ C-States |
| `max_cstate` | 1 | æœ€å¤§ C-State (C0/C1 only) |
| `thp_enabled` | "always" | Transparent Huge Pages |
| `vm_swappiness` | 10 | å†…å­˜äº¤æ¢å€¾å‘å€¼ |
| `install_perf_service` | true | å®‰è£…æ€§èƒ½è°ƒä¼˜æœåŠ¡ |

### è‡ªå®šä¹‰é…ç½®

å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®è¦†ç›–é»˜è®¤é…ç½®ï¼š

1. `ansible/inventory/group_vars/gpu_nodes.yml` - ç»„çº§åˆ«å˜é‡
2. `ansible/inventory/hosts.yml` - ä¸»æœºçº§åˆ«å˜é‡
3. å‘½ä»¤è¡Œå‚æ•°: `-e "variable=value"`

## éªŒè¯æŠ¥å‘Š

éªŒè¯å®Œæˆåï¼ŒæŠ¥å‘Šä¼šä¿å­˜åœ¨ï¼š

- **ç›®æ ‡ä¸»æœº**: `/tmp/gpu_validation/`
- **æ§åˆ¶èŠ‚ç‚¹**: `./validation_results/<hostname>/`

æŠ¥å‘Šæ ¼å¼ï¼š
- JSON æ ¼å¼ï¼šè¯¦ç»†çš„ç»“æ„åŒ–æ•°æ®
- æ–‡æœ¬æ ¼å¼ï¼šå¯è¯»çš„éªŒè¯æ‘˜è¦
- HTML æ ¼å¼ï¼šå¯è§†åŒ–æŠ¥å‘Šï¼ˆå®Œæ•´éªŒè¯ï¼‰

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**1. nvidia-smi ä¸å¯ç”¨**
```bash
# æ£€æŸ¥é©±åŠ¨æ˜¯å¦åŠ è½½
lsmod | grep nvidia

# æ£€æŸ¥ nouveau æ˜¯å¦è¢«ç¦ç”¨
lsmod | grep nouveau

# é‡æ–°è¿è¡ŒåŸºçº¿å®‰è£…
ansible-playbook playbooks/setup_gpu_baseline.yml
```

**2. å®¹å™¨æ— æ³•è®¿é—® GPU**
```bash
# æ£€æŸ¥ NVIDIA Container Toolkit
docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi

# æ£€æŸ¥ Docker daemon é…ç½®
cat /etc/docker/daemon.json
```

**3. GPU æ¸©åº¦è¿‡é«˜**
```bash
# æ£€æŸ¥æ•£çƒ­
nvidia-smi -q -d TEMPERATURE

# è°ƒæ•´åŠŸç‡é™åˆ¶
nvidia-smi -pl 250  # è®¾ç½®ä¸º 250W
```

## ğŸ†• 2024-2025 æœ€æ–°å·¥å…·å’ŒæŠ€æœ¯

### NVIDIA å®˜æ–¹æœ€æ–°å·¥å…·

#### NVIDIA DeepOps (è£¸é‡‘å±é›†ç¾¤éƒ¨ç½²)
- **é¡¹ç›®**: https://github.com/NVIDIA/deepops
- **ç‰ˆæœ¬**: 22.04.1 (æŒç»­ç»´æŠ¤)
- **ç”¨é€”**: GPU é›†ç¾¤éƒ¨ç½²æœ€ä½³å®è·µï¼Œæ”¯æŒ Kubernetes å’Œ Slurm
- **ç‰¹ç‚¹**: è£¸é‡‘å±ä¼˜åŒ–ã€DGX ç³»ç»Ÿæ”¯æŒã€å®Œæ•´ç›‘æ§æ ˆ

#### NVIDIA GPU Operator (Kubernetes)
- **2024-2025 æœ€æ´»è·ƒé¡¹ç›®**
- **ç”¨é€”**: Kubernetes GPU ç®¡ç†æ ‡å‡†åŒ–
- **ç‰¹æ€§**: vGPUã€MIGã€Time Slicingã€GPUDirect RDMA/Storage

#### NVIDIA Dynamo (2025 å¹´æ–°å·¥å…·)
- **å‘å¸ƒ**: 2025 å¹´åˆ
- **åˆ›æ–°**: AI æ¨ç†æ„ŸçŸ¥çš„è‡ªåŠ¨æ‰©å±•å™¨
- **ç‰¹æ€§**: å•å‘½ä»¤éƒ¨ç½²åˆ°æ•°åƒ GPUã€åŠ¨æ€èµ„æºç®¡ç†

#### NVIDIA KAI Scheduler (2025 å¹´å¼€æº)
- **å‘å¸ƒ**: 2025 å¹´ 1 æœˆ
- **ç”¨é€”**: ä¼ä¸šçº§ GPU è°ƒåº¦å™¨
- **ç‰¹ç‚¹**: Kubernetes AI å·¥ä½œè´Ÿè½½ä¼˜åŒ–

### CPU ä¼˜åŒ–å‚è€ƒèµ„æº

- **PyTorch Performance Tuning**: https://docs.pytorch.org/tutorials/recipes/recipes/tuning_guide.html
- **NVIDIA Triton Optimization**: https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/optimization.html
- **AMD ROCm System Optimization**: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/
- **Intel VTune NUMA Analysis**: https://www.intel.com/content/www/us/en/docs/vtune-profiler/cookbook/

## å¼€æºé¡¹ç›®å‚è€ƒ

æœ¬é¡¹ç›®æ•´åˆäº†ä»¥ä¸‹ä¼˜ç§€çš„å¼€æºé¡¹ç›®å’Œå·¥å…·ï¼š

### Ansible Roles
- [NVIDIA/ansible-role-nvidia-driver](https://github.com/NVIDIA/ansible-role-nvidia-driver)
- [NVIDIA/ansible-role-nvidia-docker](https://github.com/NVIDIA/ansible-role-nvidia-docker)
- [NVIDIA/deepops](https://github.com/NVIDIA/deepops) - ğŸ†• 2024-2025 æ¨è
- [CSCfi/ansible-role-cuda](https://github.com/fgci-org/ansible-role-cuda)
- [Provizanta/ansible-role-nvidia-cuda](https://github.com/Provizanta/ansible-role-nvidia-cuda)
- [datadrivers/ansible-role-docker](https://github.com/datadrivers/ansible-role-docker)

### éªŒè¯å’Œç›‘æ§å·¥å…·
- [NVIDIA DCGM](https://github.com/NVIDIA/DCGM)
- [NVIDIA GPU Stress Test](https://github.com/NVIDIA/GPUStressTest)
- [GPU-Burn](https://github.com/wilicc/gpu-burn)
- [gpustat](https://github.com/wookayin/gpustat)
- [nvitop](https://github.com/XuehaiPan/nvitop)
- [GPUtil](https://github.com/anderskm/gputil)

### æ–‡æ¡£å’ŒæŒ‡å—
- [NVIDIA Validation Suite User Guide](https://docs.nvidia.com/deploy/nvvs-user-guide/)
- [DCGM User Guide](https://docs.nvidia.com/datacenter/dcgm/latest/user-guide/)
- [NVIDIA GPU Operator Docs](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/)

## æ–‡æ¡£

- [å¼€æºé¡¹ç›®è°ƒç ”æŠ¥å‘Š](docs/research.md) - è¯¦ç»†çš„å¼€æºé¡¹ç›®è°ƒç ”å’Œåˆ†æ
- [ğŸ†• 2024-2025 æœ€æ–°è°ƒç ”](docs/latest_research_2025.md) - æœ€æ–°å·¥å…·ã€CPU ä¼˜åŒ–ã€BIOS é…ç½®å®Œæ•´æŒ‡å—
- [å®æ–½æ–¹æ¡ˆ](docs/implementation_plan.md) - å®Œæ•´çš„æŠ€æœ¯å®æ–½æ–¹æ¡ˆ

## ğŸ†• å…³é”® BIOS é…ç½®å»ºè®®

åŸºäº 2024-2025 æœ€ä½³å®è·µï¼Œä»¥ä¸‹ BIOS è®¾ç½®å¯æ˜¾è‘—æå‡ GPU æ€§èƒ½ï¼š

### CPU é…ç½®
```
Intel Hyper-Threading / AMD SMT: Enabled
Intel Turbo Boost / AMD Core Performance Boost: Enabled
Intel SpeedStep / AMD Cool'n'Quiet: Disabled
C-States: Disabled (æˆ– C1E Only)
CPU Power Policy: Maximum Performance
```

### å†…å­˜é…ç½®
```
NUMA: Enabled
NUMA Nodes per Socket (NPS): 4 (AMD EPYC, HPC workloads)
Memory Interleaving: Disabled
```

### PCIe å’Œ I/O
```
PCIe Link Speed: Gen 4 / Gen 5 (Max)
PCIe ASPM: Disabled
PCIe ACS: Enabled
VT-d (Intel) / IOMMU (AMD): Enabled
Above 4G Decoding: Enabled
Resizable BAR: Enabled
SR-IOV Support: Enabled
```

è¯¦ç»† BIOS é…ç½®æŒ‡å—è¯·å‚è€ƒ: [docs/latest_research_2025.md](docs/latest_research_2025.md#å››å®Œæ•´çš„-bios-é…ç½®æ¨è)

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚

## è‡´è°¢

æ„Ÿè°¢ NVIDIA å’Œå¼€æºç¤¾åŒºæä¾›çš„ä¼˜ç§€å·¥å…·å’Œæœ€ä½³å®è·µã€‚

---

**é¡¹ç›®ç»´æŠ¤è€…**: è¯·æ ¹æ®å®é™…æƒ…å†µæ›´æ–°

**æœ€åæ›´æ–°**: 2025-01-15
