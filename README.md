# GPU Passthrough - åŸºçº¿å®‰è£…ä¸éªŒè¯è‡ªåŠ¨åŒ– (2025 ç‰ˆæœ¬)

è¿™ä¸ªé¡¹ç›®æä¾›åŸºäº Ansible çš„ GPU æœºå™¨åŸºçº¿å®‰è£…å’ŒéªŒè¯è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆï¼ŒåŸºäº NVIDIA å®˜æ–¹å·¥å…·å’Œ 2024-2025 å¹´æœ€æ–°çš„å¼€æºç¤¾åŒºæœ€ä½³å®è·µã€‚

> **ğŸ†• 2025 å¹´æ›´æ–°**: æ–°å¢ CPU æ€§èƒ½ä¼˜åŒ–ã€NUMA é…ç½®ã€å®Œæ•´ç³»ç»ŸéªŒè¯ã€é€šè®¯å¸¦å®½æµ‹è¯•ã€æ¨¡å‹è®­ç»ƒåŸºå‡†æµ‹è¯•ã€GPU-CUDA å…¼å®¹æ€§è‡ªåŠ¨åŒ¹é…ã€NGC å®¹å™¨é•œåƒç®¡ç†

## é¡¹ç›®ç›®æ ‡

1. **è‡ªåŠ¨åŒ–å®‰è£…**: é€šè¿‡ Ansible è‡ªåŠ¨åŒ–å®‰è£… GPU æœºå™¨çš„åŸºçº¿ç¯å¢ƒï¼ˆé©±åŠ¨ã€CUDAã€å®¹å™¨è¿è¡Œæ—¶ï¼‰
2. **ğŸ†• æ™ºèƒ½ CUDA é€‰æ‹©**: è‡ªåŠ¨æ£€æµ‹ GPU å‹å·å¹¶é€‰æ‹©å¯¹åº”çš„ CUDA å’Œé©±åŠ¨ç‰ˆæœ¬
3. **CPU æ€§èƒ½ä¼˜åŒ–**: ä¼˜åŒ– CPU é…ç½®ä»¥æœ€å¤§åŒ– GPU å·¥ä½œè´Ÿè½½æ€§èƒ½ï¼ˆNUMAã€é¢‘ç‡è°ƒèŠ‚ã€Turbo Boost ç­‰ï¼‰
4. **å…¨é¢éªŒè¯**: æä¾›å¤šçº§åˆ«çš„éªŒè¯è„šæœ¬ï¼Œæ£€æŸ¥ CPUã€GPUã€NUMAã€IOMMUã€PCIe ç­‰æ‰€æœ‰é…ç½®
5. **ğŸ†• é€šè®¯å¸¦å®½æµ‹è¯•**: PCIeã€NVLinkã€RDMA å¸¦å®½æµ‹è¯•ï¼Œä¸æ€§èƒ½åŸºçº¿å¯¹æ¯”
6. **ğŸ†• æ¨¡å‹è®­ç»ƒåŸºå‡†**: NCCL é›†åˆé€šä¿¡æµ‹è¯•ã€Megatron-LM è®­ç»ƒååé‡æµ‹è¯•
7. **ğŸ†• NGC å®¹å™¨ç®¡ç†**: è‡ªåŠ¨åŒ–æ‹‰å–å’Œç®¡ç† NVIDIA NGC é•œåƒï¼ˆPyTorchã€NeMoã€Triton ç­‰ï¼‰
8. **å¼€æºæ•´åˆ**: åŸºäº NVIDIA DeepOpsã€GPU Operator ç­‰ 2024-2025 å¹´æœ€æ–°å·¥å…·å’Œæœ€ä½³å®è·µ

## é¡¹ç›®ç»“æ„

```
gpu_passthrough/
â”œâ”€â”€ ansible/                    # Ansible è‡ªåŠ¨åŒ–é…ç½®
â”‚   â”œâ”€â”€ roles/
â”‚   â”‚   â”œâ”€â”€ gpu_baseline/      # GPU åŸºçº¿å®‰è£… role (å« GPU è‡ªåŠ¨æ£€æµ‹)
â”‚   â”‚   â”œâ”€â”€ cpu_optimization/  # ğŸ†• CPU æ€§èƒ½ä¼˜åŒ– role
â”‚   â”‚   â”œâ”€â”€ benchmark_tools/   # ğŸ†• åŸºå‡†æµ‹è¯•å·¥å…· role
â”‚   â”‚   â”œâ”€â”€ ngc_images/        # ğŸ†• NGC å®¹å™¨é•œåƒç®¡ç† role
â”‚   â”‚   â””â”€â”€ gpu_validation/    # GPU éªŒè¯ role
â”‚   â”œâ”€â”€ playbooks/
â”‚   â”‚   â”œâ”€â”€ setup_gpu_baseline.yml           # GPU åŸºçº¿å®‰è£…
â”‚   â”‚   â”œâ”€â”€ full_deployment_optimized.yml    # ğŸ†• å®Œæ•´ä¼˜åŒ–éƒ¨ç½²
â”‚   â”‚   â””â”€â”€ validate_gpu.yml                 # GPU éªŒè¯
â”‚   â”œâ”€â”€ inventory/             # ä¸»æœºæ¸…å•
â”‚   â””â”€â”€ ansible.cfg
â”œâ”€â”€ scripts/                    # éªŒè¯å’Œç›‘æ§è„šæœ¬
â”‚   â”œâ”€â”€ install/               # ğŸ†• å®‰è£…è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ install_gpu_driver.sh  # ğŸ†• GPU é©±åŠ¨å®‰è£…è„šæœ¬ï¼ˆå¤šæ–¹æ³•æ”¯æŒï¼‰
â”‚   â”‚   â””â”€â”€ build_precompiled_driver.sh # ğŸ†• é¢„ç¼–è¯‘é©±åŠ¨æ„å»ºè„šæœ¬
â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”œâ”€â”€ quick_check.sh     # å¿«é€ŸéªŒè¯
â”‚   â”‚   â”œâ”€â”€ system_check.sh    # ğŸ†• å…¨é¢ç³»ç»ŸéªŒè¯
â”‚   â”‚   â”œâ”€â”€ bandwidth_test.sh  # ğŸ†• å¸¦å®½æµ‹è¯•
â”‚   â”‚   â””â”€â”€ gpu_health.py      # GPU å¥åº·æ£€æŸ¥
â”‚   â”œâ”€â”€ benchmarks/            # ğŸ†• åŸºå‡†æµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ nccl_benchmark.sh  # NCCL æµ‹è¯•
â”‚   â”‚   â””â”€â”€ megatron_benchmark.sh # Megatron è®­ç»ƒåŸºå‡†
â”‚   â”œâ”€â”€ utils/                 # å·¥å…·è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ performance_baselines.py # æ€§èƒ½åŸºçº¿æ•°æ®åº“
â”‚   â”‚   â”œâ”€â”€ cuda_compatibility.py    # ğŸ†• GPU-CUDA å…¼å®¹æ€§æ•°æ®åº“
â”‚   â”‚   â”œâ”€â”€ ngc_images.py            # ğŸ†• NGC é•œåƒæ³¨å†Œè¡¨
â”‚   â”‚   â””â”€â”€ ngc_manager.sh           # ğŸ†• NGC é•œåƒç®¡ç†å·¥å…·
â”‚   â””â”€â”€ monitoring/            # ç›‘æ§è„šæœ¬
â”œâ”€â”€ docs/                       # æ–‡æ¡£
â”‚   â”œâ”€â”€ research.md            # å¼€æºé¡¹ç›®è°ƒç ”æŠ¥å‘Š
â”‚   â”œâ”€â”€ latest_research_2025.md # ğŸ†• 2024-2025 æœ€æ–°è°ƒç ”
â”‚   â”œâ”€â”€ bandwidth_and_benchmarks.md # ğŸ†• å¸¦å®½æµ‹è¯•å’ŒåŸºå‡†æµ‹è¯•æŒ‡å—
â”‚   â”œâ”€â”€ cuda_compatibility_and_ngc.md # ğŸ†• CUDA å…¼å®¹æ€§å’Œ NGC é•œåƒæŒ‡å—
â”‚   â”œâ”€â”€ gpu_driver_installation_methods.md # ğŸ†• GPU é©±åŠ¨å®‰è£…æ–¹æ³•æŒ‡å—
â”‚   â””â”€â”€ implementation_plan.md # å®æ–½æ–¹æ¡ˆ
â””â”€â”€ README.md
```

## æ ¸å¿ƒåŠŸèƒ½

### 1. GPU åŸºçº¿å®‰è£… (gpu_baseline role)

è‡ªåŠ¨åŒ–å®‰è£…ä»¥ä¸‹ç»„ä»¶ï¼š

- âœ… NVIDIA GPU é©±åŠ¨ï¼ˆæ”¯æŒå¤šç§å®‰è£…æ–¹æ³•ï¼‰
- âœ… CUDA Toolkit
- âœ… NVIDIA Container Toolkit (Docker/containerd)
- âœ… GPU é…ç½®ä¼˜åŒ–ï¼ˆæŒä¹…åŒ–æ¨¡å¼ã€åŠŸç‡é™åˆ¶ç­‰ï¼‰
- âœ… ğŸ†• **GPU è‡ªåŠ¨æ£€æµ‹**: è‡ªåŠ¨è¯†åˆ« GPU å‹å·å¹¶é€‰æ‹©å¯¹åº”çš„ CUDA å’Œé©±åŠ¨ç‰ˆæœ¬
- âœ… ğŸ†• **å¤šç§å®‰è£…æ–¹æ³•**: Nativeã€Driver Containerã€Precompiled

**ğŸ†• GPU-CUDA å…¼å®¹æ€§è‡ªåŠ¨åŒ¹é…**:

æ”¯æŒçš„ GPU å‹å·å’Œè‡ªåŠ¨é€‰æ‹©çš„ CUDA ç‰ˆæœ¬ï¼š

| GPU æ¶æ„ | GPU å‹å· | æ¨è CUDA | æ¨èé©±åŠ¨ |
|---------|---------|-----------|----------|
| Volta | V100 | 12.2 | 535.154.05 |
| Ampere | A100, A800, RTX 3090 | 12.2 | 535.154.05 |
| Hopper | H100, H800 | 12.3 | 545.23.08 |
| Ada Lovelace | RTX 4090 | 12.2 | 535.154.05 |

```bash
# å¯ç”¨è‡ªåŠ¨æ£€æµ‹ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
auto_detect_cuda_version: true

# Ansible ä¼šè‡ªåŠ¨ï¼š
# 1. æ£€æµ‹ GPU å‹å·ï¼ˆlspciï¼‰
# 2. æŸ¥è¯¢å…¼å®¹æ€§æ•°æ®åº“
# 3. é€‰æ‹©æ¨èçš„ CUDA ç‰ˆæœ¬å’Œé©±åŠ¨ç‰ˆæœ¬
# 4. è®°å½•æ£€æµ‹æŠ¥å‘Šåˆ° /var/log/gpu_baseline/gpu_detection.txt
```

**ğŸ†• GPU é©±åŠ¨å®‰è£…æ–¹æ³•**:

æ”¯æŒä¸‰ç§é©±åŠ¨å®‰è£…æ–¹å¼ï¼ŒåŸºäº NVIDIA GPU Operator æ¶æ„ï¼š

| æ–¹æ³• | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| **Native** | ä¼ ç»Ÿå®‰è£…ï¼Œç›´æ¥åœ¨ç³»ç»Ÿä¸Šå®‰è£…é©±åŠ¨ | ä¼ ç»Ÿæ•°æ®ä¸­å¿ƒã€ç‰©ç†æœåŠ¡å™¨ |
| **Driver Container** | å®¹å™¨åŒ–é©±åŠ¨ï¼ŒåŸºäº GPU Operator | Kubernetesã€äº‘åŸç”Ÿç¯å¢ƒ |
| **Precompiled** | é¢„ç¼–è¯‘é©±åŠ¨ï¼Œå¿«é€Ÿéƒ¨ç½² | å¤§è§„æ¨¡éƒ¨ç½²ã€å†…æ ¸ç»Ÿä¸€ç¯å¢ƒ |

```bash
# æ–¹æ³• 1: Native å®‰è£…ï¼ˆé»˜è®¤ï¼‰
ansible-playbook -i inventory/hosts playbooks/setup_gpu_baseline.yml \
  -e "driver_installation_method=native"

# æ–¹æ³• 2: Driver Container å®‰è£…
ansible-playbook -i inventory/hosts playbooks/setup_gpu_baseline.yml \
  -e "driver_installation_method=driver-container"

# æ–¹æ³• 3: ä½¿ç”¨ç‹¬ç«‹è„šæœ¬å®‰è£…
sudo ./scripts/install/install_gpu_driver.sh --method native --auto-detect
sudo ./scripts/install/install_gpu_driver.sh --method driver-container
sudo ./scripts/install/install_gpu_driver.sh --method precompiled
```

**è¯¦ç»†æ–‡æ¡£**:
- [GPU é©±åŠ¨å®‰è£…æ–¹æ³•æŒ‡å—](docs/gpu_driver_installation_methods.md) - ä¸‰ç§æ–¹æ³•çš„è¯¦ç»†å¯¹æ¯”å’Œä½¿ç”¨æŒ‡å—
- [é¢„ç¼–è¯‘é©±åŠ¨å®Œæ•´æŒ‡å—](docs/precompiled_driver_guide.md) - é¢„ç¼–è¯‘é©±åŠ¨çš„æ„å»ºã€éƒ¨ç½²å’Œç®¡ç†

**ğŸ†• é¢„ç¼–è¯‘é©±åŠ¨ç‰¹æ€§**:

é¢„ç¼–è¯‘é©±åŠ¨æä¾›æœ€å¿«çš„éƒ¨ç½²é€Ÿåº¦å’Œæœ€ä½çš„èµ„æºæ¶ˆè€—ï¼Œç‰¹åˆ«é€‚åˆå¤§è§„æ¨¡éƒ¨ç½²ï¼š

```bash
# æ„å»ºé¢„ç¼–è¯‘é©±åŠ¨ï¼ˆä¸€æ¬¡æ€§ï¼‰
./scripts/install/build_precompiled_driver.sh \
    --driver-version 535.154.05 \
    --kernel-version 5.15.0-91-generic \
    --container-build

# æ‰¹é‡æ„å»ºå¤šä¸ªç‰ˆæœ¬
./scripts/install/batch_build_drivers.sh

# ç®¡ç†é¢„ç¼–è¯‘é©±åŠ¨
./scripts/utils/manage_precompiled_drivers.sh list          # åˆ—å‡ºæ‰€æœ‰å¯ç”¨é©±åŠ¨
./scripts/utils/manage_precompiled_drivers.sh install 535.154.05  # å®‰è£…æŒ‡å®šç‰ˆæœ¬
./scripts/utils/manage_precompiled_drivers.sh rollback      # å›æ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬
```

**æ€§èƒ½å¯¹æ¯”**ï¼ˆ100 èŠ‚ç‚¹é›†ç¾¤ï¼‰:

| æŒ‡æ ‡ | ä¼ ç»Ÿå®‰è£… | é¢„ç¼–è¯‘é©±åŠ¨ | èŠ‚çœ |
|------|---------|-----------|------|
| éƒ¨ç½²æ—¶é—´ | ~50 å°æ—¶ | ~3.5 å°æ—¶ | 93% |
| CPU æ—¶é—´ | 100 åˆ†é’Ÿ/èŠ‚ç‚¹ | 5 åˆ†é’Ÿ/èŠ‚ç‚¹ | 95% |
| å†…å­˜ä½¿ç”¨ | 4 GB | 512 MB | 87% |
| ç½‘ç»œå¸¦å®½ | 200 MB/èŠ‚ç‚¹ | 50 MB/èŠ‚ç‚¹ | 75% |

**åŸºäºçš„å¼€æºé¡¹ç›®**:
- [NVIDIA/ansible-role-nvidia-driver](https://github.com/NVIDIA/ansible-role-nvidia-driver)
- [NVIDIA/ansible-role-nvidia-docker](https://github.com/NVIDIA/ansible-role-nvidia-docker)
- [CSCfi/ansible-role-cuda](https://github.com/fgci-org/ansible-role-cuda)
- [datadrivers/ansible-role-docker](https://github.com/datadrivers/ansible-role-docker)

### 2. ğŸ†• CPU æ€§èƒ½ä¼˜åŒ– (cpu_optimization role)

**é’ˆå¯¹ GPU å·¥ä½œè´Ÿè½½ä¼˜åŒ– CPU é…ç½®**ï¼Œæ€§èƒ½æå‡ 20-40%ï¼š

- âœ… CPU Governor è®¾ç½®ï¼ˆPerformance æ¨¡å¼ï¼‰
- âœ… Turbo Boost / Turbo Core å¯ç”¨
- âœ… NUMA ä¼˜åŒ–å’Œäº²å’Œæ€§é…ç½®
- âœ… C-States ä¼˜åŒ–ï¼ˆé™ä½å»¶è¿Ÿï¼‰
- âœ… IOMMU é…ç½®ï¼ˆIntel VT-d / AMD-Viï¼‰
- âœ… PCIe æ€§èƒ½ä¼˜åŒ–
- âœ… Transparent Huge Pages é…ç½®
- âœ… å†…å­˜å‚æ•°è°ƒä¼˜ï¼ˆswappinessã€dirty ratioï¼‰

**å…³é”®ä¼˜åŒ–é¡¹**:
| ä¼˜åŒ–é¡¹ | é»˜è®¤å€¼ | ä¼˜åŒ–å€¼ | æ€§èƒ½æå‡ |
|--------|--------|--------|----------|
| CPU Governor | ondemand/powersave | performance | 10-20% |
| NUMA é…ç½® | è‡ªåŠ¨ | ç»‘å®šåˆ°å¯¹åº”èŠ‚ç‚¹ | 20-40% |
| Turbo Boost | æœªçŸ¥ | å¼ºåˆ¶å¯ç”¨ | 10-15% |
| C-States | æ·±åº¦ç¡çœ  | C1 only | 5-10% (é™ä½å»¶è¿Ÿ) |

**åŸºäºæœ€ä½³å®è·µ**:
- NVIDIA DeepOps é…ç½®
- PyTorch/TensorFlow æ€§èƒ½è°ƒä¼˜æŒ‡å—
- AMD ROCm ç³»ç»Ÿä¼˜åŒ–æ–‡æ¡£

### 3. ğŸ†• å…¨é¢ç³»ç»ŸéªŒè¯ (system_check.sh)

**å®Œæ•´çš„ç³»ç»Ÿé…ç½®éªŒè¯**ï¼Œæ¶µç›– 8 å¤§ç±»æ£€æŸ¥é¡¹ï¼š

1. **CPU é…ç½®**: Governorã€Turbo Boostã€é¢‘ç‡ã€C-States
2. **NUMA é…ç½®**: èŠ‚ç‚¹æ•°ã€GPU äº²å’Œæ€§ã€æ‹“æ‰‘ç»“æ„
3. **IOMMU é…ç½®**: VT-d/AMD-Vi å¯ç”¨ã€IOMMU ç»„ã€å†…æ ¸å‚æ•°
4. **PCIe é…ç½®**: é“¾è·¯é€Ÿåº¦ã€å®½åº¦ã€é”™è¯¯è®¡æ•°ã€ACS
5. **GPU é…ç½®**: é©±åŠ¨ç‰ˆæœ¬ã€æŒä¹…åŒ–æ¨¡å¼ã€æ¸©åº¦ã€ECC é”™è¯¯
6. **å†…å­˜é…ç½®**: THPã€swappinessã€dirty ratio
7. **å†…æ ¸å‚æ•°**: GRUB é…ç½®æ£€æŸ¥
8. **å®¹å™¨è¿è¡Œæ—¶**: Docker/containerd GPU è®¿é—®æµ‹è¯•

**éªŒè¯è¾“å‡º**:
- JSON æ ¼å¼è¯¦ç»†æŠ¥å‘Š
- å½©è‰²ç»ˆç«¯è¾“å‡ºï¼ˆâœ“ é€šè¿‡ / âš  è­¦å‘Š / âœ— å¤±è´¥ï¼‰
- è‡ªåŠ¨åŒ–å¯é›†æˆåˆ° CI/CD

### 4. ğŸ†• é€šè®¯å¸¦å®½æµ‹è¯• (bandwidth_test.sh)

**å®Œæ•´çš„é€šè®¯å¸¦å®½æµ‹è¯•å’Œæ€§èƒ½åŸºçº¿å¯¹æ¯”**ï¼š

#### æœºå†…é€šè®¯æµ‹è¯•
- âœ… **PCIe å¸¦å®½**: Host-Device å’Œ Device-Host ä¼ è¾“ï¼ˆä½¿ç”¨ nvbandwidth, bandwidthTestï¼‰
- âœ… **NVLink å¸¦å®½**: GPU-GPU P2P ä¼ è¾“ï¼ˆä½¿ç”¨ p2pBandwidthLatencyTestï¼‰
- âœ… **GPU æ‹“æ‰‘**: è‡ªåŠ¨æ£€æµ‹ NVLink è¿æ¥å’Œ PCIe é…ç½®

#### æœºé—´é€šè®¯æµ‹è¯•
- âœ… **RDMA å¸¦å®½**: InfiniBand/RoCE ç½‘ç»œæ€§èƒ½ï¼ˆä½¿ç”¨ ib_write_bwï¼‰
- âœ… **GPUDirect RDMA**: GPU ç›´æ¥è®¿é—®è¿œç¨‹ GPU å†…å­˜
- âœ… **ç½‘ç»œæ‹“æ‰‘**: è‡ªåŠ¨æ£€æµ‹ IB è®¾å¤‡å’Œé“¾è·¯é€Ÿåº¦

#### æ€§èƒ½åŸºçº¿æ•°æ®åº“

| GPU å‹å· | å†…å­˜å¸¦å®½ | NVLink BW | PCIe BW | AllReduce (8GPU) |
|---------|---------|-----------|---------|------------------|
| A100-SXM4-80GB | 2039 GB/s | 600 GB/s | 64 GB/s | 250 GB/s |
| H100-SXM5-80GB | 3350 GB/s | 900 GB/s | 128 GB/s | 450 GB/s |
| V100-SXM2-32GB | 900 GB/s | 300 GB/s | 32 GB/s | 180 GB/s |

**ä½¿ç”¨æ–¹å¼**:
```bash
# è¿è¡Œå®Œæ•´å¸¦å®½æµ‹è¯•
./scripts/validation/bandwidth_test.sh

# æˆ–ä½¿ç”¨å¿«æ·å‘½ä»¤ï¼ˆå®‰è£…åï¼‰
gpu-benchmark bandwidth

# æŸ¥çœ‹æ€§èƒ½åŸºçº¿
python3 scripts/utils/performance_baselines.py list
python3 scripts/utils/performance_baselines.py info A100-SXM4-80GB
```

### 5. ğŸ†• NCCL é›†åˆé€šä¿¡æµ‹è¯• (nccl_benchmark.sh)

**æµ‹è¯•åˆ†å¸ƒå¼è®­ç»ƒçš„é›†åˆé€šä¿¡æ€§èƒ½**ï¼š

- âœ… **AllReduce**: æœ€å¸¸ç”¨çš„æ¢¯åº¦åŒæ­¥æ“ä½œ
- âœ… **Broadcast**: å‚æ•°å¹¿æ’­æ€§èƒ½
- âœ… **Reduce-Scatter**: åˆ†å¸ƒå¼ reduce æ“ä½œ
- âœ… **All-Gather**: æ”¶é›†æ“ä½œæ€§èƒ½
- âœ… **å¤šèŠ‚ç‚¹æ”¯æŒ**: MPI é›†æˆï¼Œæ”¯æŒè·¨èŠ‚ç‚¹æµ‹è¯•
- âœ… **æ€§èƒ½åŸºçº¿å¯¹æ¯”**: è‡ªåŠ¨å¯¹æ¯”é¢„æœŸæ€§èƒ½

**é¢„æœŸæ€§èƒ½ï¼ˆBus Bandwidthï¼‰**:
- **A100 8-GPU èŠ‚ç‚¹å†…**: ~250 GB/s
- **H100 8-GPU èŠ‚ç‚¹å†…**: ~450 GB/s
- **A100 è·¨èŠ‚ç‚¹ (IB HDR)**: ~180 GB/s

**ä½¿ç”¨æ–¹å¼**:
```bash
# å•èŠ‚ç‚¹ NCCL æµ‹è¯•
./scripts/benchmarks/nccl_benchmark.sh

# æˆ–ä½¿ç”¨å¿«æ·å‘½ä»¤
gpu-benchmark nccl

# å¤šèŠ‚ç‚¹æµ‹è¯•ï¼ˆéœ€è¦ MPIï¼‰
mpirun -np 64 -N 8 --hostfile hosts \
    /opt/nccl-tests/build/all_reduce_perf -b 8 -e 8G -f 2 -g 1
```

### 6. ğŸ†• Megatron-LM è®­ç»ƒåŸºå‡† (megatron_benchmark.sh)

**å®é™…æ¨¡å‹è®­ç»ƒæ€§èƒ½æµ‹è¯•**ï¼š

- âœ… **GPT æ¨¡å‹è®­ç»ƒ**: æ”¯æŒ GPT-1.2B, GPT-8.3B, GPT-175B
- âœ… **TFLOPS æµ‹é‡**: å®é™…è®¡ç®—ååé‡
- âœ… **MFU è®¡ç®—**: Model FLOP Utilizationï¼ˆæ¨¡å‹åˆ©ç”¨ç‡ï¼‰
- âœ… **æ‰©å±•æ€§æµ‹è¯•**: å¤š GPU/å¤šèŠ‚ç‚¹æ€§èƒ½
- âœ… **æ€§èƒ½åŸºçº¿å¯¹æ¯”**: ä¸å·²çŸ¥åŸºå‡†å¯¹æ¯”
- âœ… **ğŸ†• NGC å®¹å™¨æ”¯æŒ**: æ”¯æŒä½¿ç”¨ NGC NeMo é•œåƒè¿è¡Œ

**æ€§èƒ½åŸºçº¿ (GPT-1.2B å• GPU)**:

| GPU å‹å· | TFLOPS | MFU | Samples/sec |
|---------|--------|-----|-------------|
| V100 | 39 | 30% | 12 |
| A100 | 93.6 | 60% | 28 |
| H100 | 178 | 47% | 45 |

**ä½¿ç”¨æ–¹å¼**:
```bash
# ä½¿ç”¨ NGC NeMo å®¹å™¨è¿è¡Œï¼ˆæ¨èï¼‰
export USE_NGC_CONTAINER=true
MODEL_SIZE=GPT-1.2B ./scripts/benchmarks/megatron_benchmark.sh

# æˆ–ä½¿ç”¨æœ¬åœ° Megatron-LM
export USE_NGC_CONTAINER=false
MODEL_SIZE=GPT-1.2B ./scripts/benchmarks/megatron_benchmark.sh

# è‡ªå®šä¹‰å‚æ•°
MODEL_SIZE=GPT-8.3B BATCH_SIZE=16 NUM_STEPS=200 \
    gpu-benchmark megatron
```

### 7. ğŸ†• NGC å®¹å™¨é•œåƒç®¡ç† (ngc_images role)

**è‡ªåŠ¨åŒ–ç®¡ç† NVIDIA NGC (GPU Cloud) å®¹å™¨é•œåƒ**ï¼š

NVIDIA NGC æä¾›é¢„ä¼˜åŒ–çš„æ·±åº¦å­¦ä¹ å’Œæ¨ç†å®¹å™¨ï¼ŒåŒ…å« CUDAã€cuDNNã€NCCL ç­‰å®Œæ•´å·¥å…·é“¾ã€‚

**æ”¯æŒçš„ NGC é•œåƒ**:

| é•œåƒ | ç‰ˆæœ¬ | ç”¨é€” | ä¸»è¦ç»„ä»¶ |
|------|------|------|----------|
| **pytorch** | 24.01 | è®­ç»ƒ/æ¨ç† | PyTorch 2.3, CUDA 12.3, TensorRT 8.6 |
| **nemo** | 24.01 | LLM è®­ç»ƒ | Megatron-LM 0.5, NeMo 1.22, Transformer Engine |
| **triton** | 24.01 | æ¨ç†æœåŠ¡ | Triton Server 2.42, TensorRT, å¤šåç«¯æ”¯æŒ |
| **tensorflow** | 24.01 | è®­ç»ƒ/æ¨ç† | TensorFlow 2.15, CUDA 12.3 |
| **tensorrt** | 24.01 | æ¨ç†ä¼˜åŒ– | TensorRT 8.6, ONNX Parser |
| **cuda** | 12.3.2 | å¼€å‘ | CUDA Toolkit, NVCC, cuBLAS |
| **rapids** | 24.02 | æ•°æ®ç§‘å­¦ | cuDF, cuML, cuGraph, Dask |
| **deepstream** | 6.4 | è§†é¢‘åˆ†æ | DeepStream, Triton é›†æˆ |

**åŠŸèƒ½ç‰¹æ€§**:

- âœ… **è‡ªåŠ¨æ‹‰å–**: åŸºäº CUDA ç‰ˆæœ¬è‡ªåŠ¨é€‰æ‹©å…¼å®¹é•œåƒ
- âœ… **GPU æµ‹è¯•**: æ‹‰å–åè‡ªåŠ¨éªŒè¯ GPU åŠŸèƒ½
- âœ… **é•œåƒç®¡ç†**: ä¾¿æ·çš„å‘½ä»¤è¡Œå·¥å…·ç®¡ç†é•œåƒ
- âœ… **æ¸…å•æŠ¥å‘Š**: è‡ªåŠ¨ç”Ÿæˆé•œåƒæ¸…å•å’Œæµ‹è¯•æŠ¥å‘Š

**ä½¿ç”¨æ–¹å¼**:

```bash
# æŸ¥çœ‹å¯ç”¨ NGC é•œåƒ
./scripts/utils/ngc_manager.sh list

# æ‹‰å– PyTorch é•œåƒ
./scripts/utils/ngc_manager.sh pull pytorch

# æ‹‰å–ç‰¹å®šç‰ˆæœ¬
./scripts/utils/ngc_manager.sh pull pytorch 24.01

# è¿è¡Œé•œåƒï¼ˆäº¤äº’å¼ï¼‰
./scripts/utils/ngc_manager.sh run pytorch

# æµ‹è¯•é•œåƒ GPU åŠŸèƒ½
./scripts/utils/ngc_manager.sh test pytorch

# æŸ¥çœ‹ CUDA 12.3 å…¼å®¹é•œåƒ
./scripts/utils/ngc_manager.sh cuda 12.3
```

**Ansible è‡ªåŠ¨åŒ–éƒ¨ç½²**:

```yaml
# ansible/roles/ngc_images/defaults/main.yml
ngc_images_to_pull:
  - name: pytorch
    version: "24.01"
  - name: nemo
    version: "24.01"
  - name: triton
    version: "24.01"

# è‡ªåŠ¨æ ¹æ® CUDA ç‰ˆæœ¬é€‰æ‹©é•œåƒ
auto_select_images_by_cuda: true
```

è¿è¡Œ playbook:
```bash
ansible-playbook -i inventory/hosts playbooks/setup_ngc_images.yml
```

**NGC é•œåƒä½¿ç”¨ç¤ºä¾‹**:

```bash
# ä½¿ç”¨ PyTorch é•œåƒè®­ç»ƒ
docker run --gpus all -it --rm \
  --ipc=host --network=host \
  -v $HOME/workspace:/workspace \
  nvcr.io/nvidia/pytorch:24.01-py3

# ä½¿ç”¨ Triton éƒ¨ç½²æ¨ç†æœåŠ¡
docker run --gpus all -it --rm \
  -p 8000:8000 -p 8001:8001 -p 8002:8002 \
  -v /path/to/models:/models \
  nvcr.io/nvidia/tritonserver:24.01-py3 \
  tritonserver --model-repository=/models
```

### 8. GPU éªŒè¯æµ‹è¯• (å¤šçº§åˆ«)

#### Level 1: å¿«é€ŸéªŒè¯ (1-5 åˆ†é’Ÿ)
- nvidia-smi å¯ç”¨æ€§æ£€æŸ¥
- GPU è®¾å¤‡æ£€æµ‹
- é©±åŠ¨å’Œ CUDA ç‰ˆæœ¬ç¡®è®¤
- åŸºç¡€å¥åº·æ£€æŸ¥ï¼ˆæ¸©åº¦ã€å†…å­˜ã€PCIeï¼‰

#### Level 2: æ ‡å‡†éªŒè¯ (10-15 åˆ†é’Ÿ)
- Level 1 æ‰€æœ‰æ£€æŸ¥
- DCGM å¿«é€Ÿè¯Šæ–­
- CUDA åŠŸèƒ½æµ‹è¯•
- å®¹å™¨ GPU è®¿é—®æµ‹è¯•
- å†…å­˜å¸¦å®½æµ‹è¯•

#### Level 3: å®Œæ•´éªŒè¯ (30-60 åˆ†é’Ÿ)
- Level 2 æ‰€æœ‰æ£€æŸ¥
- DCGM å®Œæ•´è¯Šæ–­å¥—ä»¶
- GPU-Burn å‹åŠ›æµ‹è¯•
- é•¿æ—¶é—´ç¨³å®šæ€§æµ‹è¯•
- æ€§èƒ½åŸºå‡†æµ‹è¯•

**åŸºäºçš„å·¥å…·**:
- [NVIDIA DCGM](https://github.com/NVIDIA/DCGM) - æ•°æ®ä¸­å¿ƒ GPU ç®¡ç†å™¨
- [NVIDIA Validation Suite (NVVS)](https://docs.nvidia.com/deploy/nvvs-user-guide/)
- [GPU-Burn](https://github.com/wilicc/gpu-burn) - GPU å‹åŠ›æµ‹è¯•
- [gpustat](https://github.com/wookayin/gpustat) - GPU çŠ¶æ€ç›‘æ§
- [nvitop](https://github.com/XuehaiPan/nvitop) - GPU è¿›ç¨‹ç®¡ç†

## å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

**æ§åˆ¶èŠ‚ç‚¹**:
- Ansible >= 2.10
- Python >= 3.8
- SSH è®¿é—®ç›®æ ‡ä¸»æœº

**ç›®æ ‡ä¸»æœº**:
- Ubuntu 20.04/22.04 æˆ– RHEL/CentOS 8+
- è‡³å°‘ 10GB å¯ç”¨ç£ç›˜ç©ºé—´
- NVIDIA GPU ç¡¬ä»¶
- ç®¡ç†å‘˜æƒé™

### å®‰è£…æ­¥éª¤

#### 1. å…‹éš†é¡¹ç›®

```bash
git clone <repository-url>
cd gpu_passthrough
```

#### 2. é…ç½®ä¸»æœºæ¸…å•

ç¼–è¾‘ `ansible/inventory/hosts.yml`:

```yaml
all:
  children:
    gpu_nodes:
      hosts:
        gpu-server-01:
          ansible_host: 192.168.1.101
          ansible_user: ubuntu
```

#### 3. é…ç½®å˜é‡

ç¼–è¾‘ `ansible/inventory/group_vars/gpu_nodes.yml` æ ¹æ®éœ€æ±‚è°ƒæ•´é…ç½®ï¼š

```yaml
# GPU é…ç½®
nvidia_driver_version: "535"
cuda_version: "12-2"
install_cuda: true
install_container_runtime: true
container_runtime: "docker"

# ğŸ†• CPU ä¼˜åŒ–é…ç½®
cpu_governor: "performance"
enable_turbo_boost: true
optimize_numa: true
vm_swappiness: 10
```

#### 4. ğŸ†• å®Œæ•´ä¼˜åŒ–éƒ¨ç½²ï¼ˆæ¨èï¼‰

```bash
cd ansible

# å®Œæ•´éƒ¨ç½²ï¼šGPU åŸºçº¿ + CPU ä¼˜åŒ–
ansible-playbook playbooks/full_deployment_optimized.yml

# éƒ¨ç½²åéœ€è¦é‡å¯ç³»ç»Ÿ
ssh gpu-server-01 sudo reboot
```

#### 5. ğŸ†• è¿è¡Œå…¨é¢ç³»ç»ŸéªŒè¯

```bash
# æ–¹æ³• 1: é€šè¿‡ Ansible playbook
ansible-playbook playbooks/validate_gpu.yml -e "level=standard"

# æ–¹æ³• 2: ç›´æ¥è¿è¡ŒéªŒè¯è„šæœ¬ï¼ˆåœ¨ç›®æ ‡ä¸»æœºä¸Šï¼‰
ssh gpu-server-01
sudo /path/to/scripts/validation/system_check.sh

# æ–¹æ³• 3: å¿«é€Ÿ GPU æ£€æŸ¥
./scripts/validation/quick_check.sh /tmp/gpu_check.json
```

#### æ—§æ–¹å¼ï¼šä»… GPU åŸºçº¿å®‰è£…ï¼ˆä¸å« CPU ä¼˜åŒ–ï¼‰

```bash
cd ansible
ansible-playbook playbooks/setup_gpu_baseline.yml
```

### å•ç‹¬ä½¿ç”¨éªŒè¯è„šæœ¬

```bash
# ğŸ†• å…¨é¢ç³»ç»Ÿæ£€æŸ¥ï¼ˆæ¨èï¼‰
sudo ./scripts/validation/system_check.sh /tmp/system_check.json

# GPU å¿«é€Ÿæ£€æŸ¥
./scripts/validation/quick_check.sh /tmp/gpu_check.json

# Python GPU å¥åº·æ£€æŸ¥
python3 scripts/validation/gpu_health.py -o /tmp/health_report.json -v

# ğŸ†• æŸ¥çœ‹ NUMA å’Œ GPU äº²å’Œæ€§
sudo numa-gpu-info  # éƒ¨ç½²åè‡ªåŠ¨å®‰è£…
```

## é…ç½®è¯´æ˜

### å…³é”®å˜é‡

#### GPU é…ç½®

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `nvidia_driver_version` | "535" | NVIDIA é©±åŠ¨ç‰ˆæœ¬ |
| `cuda_version` | "12-2" | CUDA Toolkit ç‰ˆæœ¬ |
| `install_cuda` | true | æ˜¯å¦å®‰è£… CUDA |
| `install_container_runtime` | true | æ˜¯å¦å®‰è£…å®¹å™¨è¿è¡Œæ—¶ |
| `container_runtime` | "docker" | å®¹å™¨è¿è¡Œæ—¶ç±»å‹ (docker/containerd) |
| `gpu_persistence_mode` | true | GPU æŒä¹…åŒ–æ¨¡å¼ |
| `validation_level` | "quick" | éªŒè¯çº§åˆ« (quick/standard/full) |

#### ğŸ†• CPU ä¼˜åŒ–é…ç½®

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `cpu_governor` | "performance" | CPU é¢‘ç‡è°ƒèŠ‚å™¨ |
| `enable_turbo_boost` | true | å¯ç”¨ Turbo Boost/Turbo Core |
| `optimize_numa` | true | å¯ç”¨ NUMA ä¼˜åŒ– |
| `disable_deep_cstates` | true | ç¦ç”¨æ·±åº¦ C-States |
| `max_cstate` | 1 | æœ€å¤§ C-State (C0/C1 only) |
| `thp_enabled` | "always" | Transparent Huge Pages |
| `vm_swappiness` | 10 | å†…å­˜äº¤æ¢å€¾å‘å€¼ |
| `install_perf_service` | true | å®‰è£…æ€§èƒ½è°ƒä¼˜æœåŠ¡ |

### è‡ªå®šä¹‰é…ç½®

å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®è¦†ç›–é»˜è®¤é…ç½®ï¼š

1. `ansible/inventory/group_vars/gpu_nodes.yml` - ç»„çº§åˆ«å˜é‡
2. `ansible/inventory/hosts.yml` - ä¸»æœºçº§åˆ«å˜é‡
3. å‘½ä»¤è¡Œå‚æ•°: `-e "variable=value"`

## éªŒè¯æŠ¥å‘Š

éªŒè¯å®Œæˆåï¼ŒæŠ¥å‘Šä¼šä¿å­˜åœ¨ï¼š

- **ç›®æ ‡ä¸»æœº**: `/tmp/gpu_validation/`
- **æ§åˆ¶èŠ‚ç‚¹**: `./validation_results/<hostname>/`

æŠ¥å‘Šæ ¼å¼ï¼š
- JSON æ ¼å¼ï¼šè¯¦ç»†çš„ç»“æ„åŒ–æ•°æ®
- æ–‡æœ¬æ ¼å¼ï¼šå¯è¯»çš„éªŒè¯æ‘˜è¦
- HTML æ ¼å¼ï¼šå¯è§†åŒ–æŠ¥å‘Šï¼ˆå®Œæ•´éªŒè¯ï¼‰

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**1. nvidia-smi ä¸å¯ç”¨**
```bash
# æ£€æŸ¥é©±åŠ¨æ˜¯å¦åŠ è½½
lsmod | grep nvidia

# æ£€æŸ¥ nouveau æ˜¯å¦è¢«ç¦ç”¨
lsmod | grep nouveau

# é‡æ–°è¿è¡ŒåŸºçº¿å®‰è£…
ansible-playbook playbooks/setup_gpu_baseline.yml
```

**2. å®¹å™¨æ— æ³•è®¿é—® GPU**
```bash
# æ£€æŸ¥ NVIDIA Container Toolkit
docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi

# æ£€æŸ¥ Docker daemon é…ç½®
cat /etc/docker/daemon.json
```

**3. GPU æ¸©åº¦è¿‡é«˜**
```bash
# æ£€æŸ¥æ•£çƒ­
nvidia-smi -q -d TEMPERATURE

# è°ƒæ•´åŠŸç‡é™åˆ¶
nvidia-smi -pl 250  # è®¾ç½®ä¸º 250W
```

## ğŸ†• 2024-2025 æœ€æ–°å·¥å…·å’ŒæŠ€æœ¯

### NVIDIA å®˜æ–¹æœ€æ–°å·¥å…·

#### NVIDIA DeepOps (è£¸é‡‘å±é›†ç¾¤éƒ¨ç½²)
- **é¡¹ç›®**: https://github.com/NVIDIA/deepops
- **ç‰ˆæœ¬**: 22.04.1 (æŒç»­ç»´æŠ¤)
- **ç”¨é€”**: GPU é›†ç¾¤éƒ¨ç½²æœ€ä½³å®è·µï¼Œæ”¯æŒ Kubernetes å’Œ Slurm
- **ç‰¹ç‚¹**: è£¸é‡‘å±ä¼˜åŒ–ã€DGX ç³»ç»Ÿæ”¯æŒã€å®Œæ•´ç›‘æ§æ ˆ

#### NVIDIA GPU Operator (Kubernetes)
- **2024-2025 æœ€æ´»è·ƒé¡¹ç›®**
- **ç”¨é€”**: Kubernetes GPU ç®¡ç†æ ‡å‡†åŒ–
- **ç‰¹æ€§**: vGPUã€MIGã€Time Slicingã€GPUDirect RDMA/Storage

#### NVIDIA Dynamo (2025 å¹´æ–°å·¥å…·)
- **å‘å¸ƒ**: 2025 å¹´åˆ
- **åˆ›æ–°**: AI æ¨ç†æ„ŸçŸ¥çš„è‡ªåŠ¨æ‰©å±•å™¨
- **ç‰¹æ€§**: å•å‘½ä»¤éƒ¨ç½²åˆ°æ•°åƒ GPUã€åŠ¨æ€èµ„æºç®¡ç†

#### NVIDIA KAI Scheduler (2025 å¹´å¼€æº)
- **å‘å¸ƒ**: 2025 å¹´ 1 æœˆ
- **ç”¨é€”**: ä¼ä¸šçº§ GPU è°ƒåº¦å™¨
- **ç‰¹ç‚¹**: Kubernetes AI å·¥ä½œè´Ÿè½½ä¼˜åŒ–

### CPU ä¼˜åŒ–å‚è€ƒèµ„æº

- **PyTorch Performance Tuning**: https://docs.pytorch.org/tutorials/recipes/recipes/tuning_guide.html
- **NVIDIA Triton Optimization**: https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/optimization.html
- **AMD ROCm System Optimization**: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/
- **Intel VTune NUMA Analysis**: https://www.intel.com/content/www/us/en/docs/vtune-profiler/cookbook/

## å¼€æºé¡¹ç›®å‚è€ƒ

æœ¬é¡¹ç›®æ•´åˆäº†ä»¥ä¸‹ä¼˜ç§€çš„å¼€æºé¡¹ç›®å’Œå·¥å…·ï¼š

### Ansible Roles
- [NVIDIA/ansible-role-nvidia-driver](https://github.com/NVIDIA/ansible-role-nvidia-driver)
- [NVIDIA/ansible-role-nvidia-docker](https://github.com/NVIDIA/ansible-role-nvidia-docker)
- [NVIDIA/deepops](https://github.com/NVIDIA/deepops) - ğŸ†• 2024-2025 æ¨è
- [CSCfi/ansible-role-cuda](https://github.com/fgci-org/ansible-role-cuda)
- [Provizanta/ansible-role-nvidia-cuda](https://github.com/Provizanta/ansible-role-nvidia-cuda)
- [datadrivers/ansible-role-docker](https://github.com/datadrivers/ansible-role-docker)

### éªŒè¯å’Œç›‘æ§å·¥å…·
- [NVIDIA DCGM](https://github.com/NVIDIA/DCGM)
- [NVIDIA GPU Stress Test](https://github.com/NVIDIA/GPUStressTest)
- [GPU-Burn](https://github.com/wilicc/gpu-burn)
- [gpustat](https://github.com/wookayin/gpustat)
- [nvitop](https://github.com/XuehaiPan/nvitop)
- [GPUtil](https://github.com/anderskm/gputil)

### æ–‡æ¡£å’ŒæŒ‡å—
- [NVIDIA Validation Suite User Guide](https://docs.nvidia.com/deploy/nvvs-user-guide/)
- [DCGM User Guide](https://docs.nvidia.com/datacenter/dcgm/latest/user-guide/)
- [NVIDIA GPU Operator Docs](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/)

## æ–‡æ¡£

- [å¼€æºé¡¹ç›®è°ƒç ”æŠ¥å‘Š](docs/research.md) - è¯¦ç»†çš„å¼€æºé¡¹ç›®è°ƒç ”å’Œåˆ†æ
- [ğŸ†• 2024-2025 æœ€æ–°è°ƒç ”](docs/latest_research_2025.md) - æœ€æ–°å·¥å…·ã€CPU ä¼˜åŒ–ã€BIOS é…ç½®å®Œæ•´æŒ‡å—
- [å®æ–½æ–¹æ¡ˆ](docs/implementation_plan.md) - å®Œæ•´çš„æŠ€æœ¯å®æ–½æ–¹æ¡ˆ

## ğŸ†• å…³é”® BIOS é…ç½®å»ºè®®

åŸºäº 2024-2025 æœ€ä½³å®è·µï¼Œä»¥ä¸‹ BIOS è®¾ç½®å¯æ˜¾è‘—æå‡ GPU æ€§èƒ½ï¼š

### CPU é…ç½®
```
Intel Hyper-Threading / AMD SMT: Enabled
Intel Turbo Boost / AMD Core Performance Boost: Enabled
Intel SpeedStep / AMD Cool'n'Quiet: Disabled
C-States: Disabled (æˆ– C1E Only)
CPU Power Policy: Maximum Performance
```

### å†…å­˜é…ç½®
```
NUMA: Enabled
NUMA Nodes per Socket (NPS): 4 (AMD EPYC, HPC workloads)
Memory Interleaving: Disabled
```

### PCIe å’Œ I/O
```
PCIe Link Speed: Gen 4 / Gen 5 (Max)
PCIe ASPM: Disabled
PCIe ACS: Enabled
VT-d (Intel) / IOMMU (AMD): Enabled
Above 4G Decoding: Enabled
Resizable BAR: Enabled
SR-IOV Support: Enabled
```

è¯¦ç»† BIOS é…ç½®æŒ‡å—è¯·å‚è€ƒ: [docs/latest_research_2025.md](docs/latest_research_2025.md#å››å®Œæ•´çš„-bios-é…ç½®æ¨è)

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚

## è‡´è°¢

æ„Ÿè°¢ NVIDIA å’Œå¼€æºç¤¾åŒºæä¾›çš„ä¼˜ç§€å·¥å…·å’Œæœ€ä½³å®è·µã€‚

---

**é¡¹ç›®ç»´æŠ¤è€…**: è¯·æ ¹æ®å®é™…æƒ…å†µæ›´æ–°

**æœ€åæ›´æ–°**: 2025-01-15
